{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T16:06:27.358753Z",
     "start_time": "2024-08-26T16:06:25.785839Z"
    }
   },
   "source": [
    "import metrics2 as metrics\n",
    "import dspy\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "import examples\n",
    "\n",
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "    \n",
    "grader = dspy.OpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            model_type=\"chat\",\n",
    "            max_tokens=2000,\n",
    "            api_key=openai_api_key\n",
    "        )\n",
    "    \n",
    "max_score = metrics.MAX_SCORE"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T16:06:27.362269Z",
     "start_time": "2024-08-26T16:06:27.359760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_input = dspy.Example()"
   ],
   "id": "a4319ae8323cd4de",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 1: Conciseness"
   ],
   "id": "403a161d8d30b1cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T16:06:27.373530Z",
     "start_time": "2024-08-26T16:06:27.362803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "short_output = dspy.Prediction(narrative='word ')\n",
    "short_result = metrics.conciseness(empty_input, short_output, max_optimal_length=10)\n",
    "assert short_result == max_score, short_result\n",
    "\n",
    "long_output = dspy.Prediction(narrative='word ' * 21)\n",
    "long_result = metrics.conciseness(empty_input, long_output, max_optimal_length=10)\n",
    "assert long_result == 0, long_result\n",
    "\n",
    "med_output = dspy.Prediction(narrative='word ' * 15)\n",
    "med_result = metrics.conciseness(empty_input, med_output, max_optimal_length=10)\n",
    "assert med_result == max_score / 2, med_result"
   ],
   "id": "9cb6db83bfc4843e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 2: Accuracy"
   ],
   "id": "79045feb8d8af121"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T16:06:27.414279Z",
     "start_time": "2024-08-26T16:06:27.373530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "accurate_result = metrics.accuracy(test_input, accurate_output, grader=grader)\n",
    "assert accurate_result == max_score, accurate_result\n",
    "\n",
    "inaccurate_output = dspy.Prediction(narrative='The size being 4 increased the prediction by 11. The color being red decreased the prediction by 9.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "incomplete_but_accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10.')\n",
    "incomplete_but_accurate_result = metrics.accuracy(test_input, incomplete_but_accurate_output, grader=grader)\n",
    "assert incomplete_but_accurate_result == max_score, incomplete_but_accurate_result"
   ],
   "id": "14168fb360045bcc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1945ff38f90>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_dataset = json.load(open(\"accuracy_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "for example in accuracy_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.accuracy(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"accuracy_score\"])\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 2.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 2.0, 4.0])\n",
    "disp.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-26T16:06:27.962161Z",
     "start_time": "2024-08-26T16:06:27.415285Z"
    }
   },
   "id": "1ac0dab2bae4fb7d",
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 3: Completeness"
   ],
   "id": "583c04d26f9b3e7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T16:06:28.519983Z",
     "start_time": "2024-08-26T16:06:27.962161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8), (Shape, Square, 3)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "complete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8. The shape being square increased the prediction by 3.')\n",
    "complete_result = metrics.completeness(test_input, complete_output, grader)\n",
    "assert complete_result == max_score, complete_result\n",
    "\n",
    "incomplete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "incomplete_result = metrics.completeness(test_input, incomplete_output, grader)\n",
    "assert incomplete_result == 0, incomplete_result"
   ],
   "id": "23379cf2fdd4aa59",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "2.0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m incomplete_output \u001B[38;5;241m=\u001B[39m dspy\u001B[38;5;241m.\u001B[39mPrediction(narrative\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m incomplete_result \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39mcompleteness(test_input, incomplete_output, grader)\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m incomplete_result \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m, incomplete_result\n",
      "\u001B[1;31mAssertionError\u001B[0m: 2.0"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.520992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "completeness_dataset = json.load(open(\"completeness_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "for example in completeness_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.completeness(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"completeness_score\"])\n",
    "    if result != example[\"completeness_score\"]:\n",
    "        print(f\"Explanation: {example['explanation']}\\nNarrative: {example['narrative']}\")\n",
    "        print(f\"Expected: {example['completeness_score']}, Got: {result}\")\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 2.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 2.0, 4.0])\n",
    "disp.plot()"
   ],
   "id": "ccb29b25ae81c281",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Finetuning\n",
    "from dspy.teleprompt import BootstrapFinetune\n",
    "\n",
    "def verify_completeness_grader_metric(gold, pred, trace=None):\n",
    "    return int(gold[\"completeness_score\"]) == int(pred[\"assessment\"])\n",
    "\n",
    "examples = []\n",
    "dspy.settings.configure(lm=grader, experimental=True)\n",
    "for example in completeness_dataset:\n",
    "    question = f\"Does the narrative contain all information from the explanation? Explanation format: {example['explanation_format']}. Explanation: {example['explanation']}\"\n",
    "    test_input = dspy.Example(question=question,\n",
    "                              narrative=example[\"narrative\"],\n",
    "                              rubric=example[\"rubric\"],\n",
    "                              completeness_score=example[\"completeness_score\"]).with_inputs(\"narrative\", \"question\", \"rubric\")\n",
    "    examples.append(test_input)\n",
    "\n",
    "program = dspy.Predict(metrics.RubricAssess)\n",
    "optimizer = BootstrapFinetune(metric=verify_completeness_grader_metric)\n",
    "optimizer.compile(program, trainset=examples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.522496Z"
    }
   },
   "id": "af6bbdbaf3996730",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 4: Fluency\n",
    "\n",
    "We test fluency with two methods:\n",
    "1. A few basic unit tests\n",
    "2. Ensuring that fluency consistently scores higher on whatever dataset is labeled gold standard dataset than on other datasets"
   ],
   "id": "f513c89283bc9ed5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.523503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "good_narratives = ['The large size increased the prediction by 100, while the green color decreased it by about 20',\n",
    "                   \"The item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\"]\n",
    "\n",
    "fluent_output = dspy.Prediction(narrative='The large size of the item increased the prediction by about 10, while the red color decreased it by 8.')\n",
    "fluent_result = metrics.fluency(empty_input, fluent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "influent_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10.5. The color being red decreased it by 8.2')\n",
    "influent_result = metrics.fluency(empty_input, influent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "assert influent_result < fluent_result\n",
    "assert fluent_result == max_score, fluent_result\n",
    "\n",
    "very_influent_output = dspy.Prediction(narrative='Size 5 10.5 color red')\n",
    "very_influent_result = metrics.fluency(empty_input, very_influent_output, grader, good_narratives=good_narratives)\n",
    "assert very_influent_result == 0, very_influent_result"
   ],
   "id": "2214a9f493150063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.524509Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "metric_verification_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "labeled_train, labeled_eval, unlabeled_train, unlabeled_eval = examples.get_data(\"gold_standards.json\")\n",
    "train_data = labeled_train + unlabeled_train\n",
    "eval_data = labeled_eval + unlabeled_eval\n",
    "max_optimal_length = max([len(d.narrative) for d in labeled_train])\n",
    "\n",
    "example_good_narratives = random.sample([d.narrative for d in labeled_train], 5)\n",
    "example_bad_narratives = random.sample([d.bad_narrative for d in labeled_train if hasattr(d, \"bad_narrative\")], 5)\n",
    "\n",
    "# Example datasets do not include a rationalization, so we skip context awareness \n",
    "ver_metrics = metrics.Metrics(\n",
    "    [\n",
    "        metrics.accuracy,\n",
    "        metrics.fluency,\n",
    "        metrics.conciseness,\n",
    "        #metrics.completeness\n",
    "    ], verbose=0, openai_key=openai_api_key,\n",
    "    metric_kwargs={\"conciseness\": {\"max_optimal_length\": max_optimal_length},\n",
    "                   \"fluency\": {\"good_narratives\": example_good_narratives, \"bad_narratives\": example_bad_narratives}}\n",
    ")\n",
    "\n",
    "for dataset in metric_verification_datasets: \n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    all_results = None\n",
    "    score = 0\n",
    "    for example in labeled_train:\n",
    "        result = ver_metrics(example, example)\n",
    "        score += result[0]\n",
    "        if all_results is None:\n",
    "            all_results = result[1]\n",
    "        else:\n",
    "            all_results += result[1]\n",
    "    print(f\"Dataset: {dataset}, Average score: {score/len(labeled_train)}/{len(ver_metrics.metric_funcs)*4.0}\")\n",
    "    print(all_results/len(labeled_train))"
   ],
   "id": "605caeedebe5ccc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 5: Context-Awareness"
   ],
   "id": "c3bfd9e3b5c0bbfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.524509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "context_aware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.',\n",
    "                                       rationalization='Large items fit more contents, making them desirable, so they increase the price. People associate red with the devil, so this color decreases the price.')\n",
    "context_aware_result = metrics.context_awareness(test_input, context_aware_output, grader)\n",
    "assert context_aware_result >= max_score/2, context_aware_result\n",
    "\n",
    "context_unaware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.', \n",
    "                                         rationalization='No idea why.')\n",
    "context_unaware_result = metrics.context_awareness(test_input, context_unaware_output, grader)\n",
    "assert context_unaware_result == 0, context_unaware_result"
   ],
   "id": "8375bcc0043ea6ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Compare Datasets\n",
    "\n",
    "In the following code block, we verify our metric functionality by comparing average score on our gold standard dataset (used to tune the metrics) to other datasets that use different styles of explanations. We expect the gold standard average score to be very close to 2*len(metrics) (since each metric is scored on a scale of 0-2), and the other datasets to be lower.\n",
    " \n",
    "TODO: We do not currently verify the context awareness metric, as the gold-standard dataset does not include a rationalization"
   ],
   "id": "ff5cda333b3fc86f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.525509Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "metric_verification_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "labeled_train, labeled_eval, unlabeled_train, unlabeled_eval = examples.get_data(\"gold_standards.json\")\n",
    "train_data = labeled_train + unlabeled_train\n",
    "eval_data = labeled_eval + unlabeled_eval\n",
    "max_optimal_length = max([len(d.narrative) for d in labeled_train])\n",
    "\n",
    "example_good_narratives = random.sample([d.narrative for d in labeled_train], 5)\n",
    "example_bad_narratives = random.sample([d.bad_narrative for d in labeled_train if hasattr(d, \"bad_narrative\")], 5)\n",
    "\n",
    "# Example datasets do not include a rationalization, so we skip context awareness \n",
    "ver_metrics = metrics.Metrics(\n",
    "    [\n",
    "        metrics.accuracy,\n",
    "        metrics.fluency,\n",
    "        metrics.conciseness,\n",
    "        #metrics.completeness\n",
    "    ], verbose=0, openai_key=openai_api_key,\n",
    "    metric_kwargs={\"conciseness\": {\"max_optimal_length\": max_optimal_length},\n",
    "                   \"fluency\": {\"good_narratives\": example_good_narratives, \"bad_narratives\": example_bad_narratives}}\n",
    ")\n",
    "\n",
    "for dataset in metric_verification_datasets: \n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    all_results = None\n",
    "    score = 0\n",
    "    for example in labeled_train:\n",
    "        result = ver_metrics(example, example)\n",
    "        score += result[0]\n",
    "        if all_results is None:\n",
    "            all_results = result[1]\n",
    "        else:\n",
    "            all_results += result[1]\n",
    "    print(f\"Dataset: {dataset}, Average score: {score/len(labeled_train)}/{len(ver_metrics.metric_funcs)*4.0}\")\n",
    "    print(all_results/len(labeled_train))"
   ],
   "id": "7b59478832886fed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Failing Cases"
   ],
   "id": "cc5f59cef2f2ca2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.526511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inaccurate_output = dspy.Prediction(narrative='The size being 5 decreased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "misleading_output = dspy.Prediction(narrative='Surprisingly, the large house size of 5 increased the predicted price')\n",
    "misleading_result = metrics.accuracy(test_input, misleading_output, grader=grader)\n",
    "assert 0 < misleading_result < 4, misleading_result"
   ],
   "id": "761fe0aa9fc2f680",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-26T16:06:28.527509Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "5c9ab560813b91c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
