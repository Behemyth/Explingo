{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:18.645418Z",
     "start_time": "2024-08-23T18:02:18.637523Z"
    }
   },
   "source": [
    "import metrics2 as metrics\n",
    "import dspy\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "import examples\n",
    "\n",
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "    \n",
    "grader = dspy.OpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            model_type=\"chat\",\n",
    "            max_tokens=2000,\n",
    "            api_key=openai_api_key,\n",
    "        )\n",
    "    \n",
    "max_score = metrics.MAX_SCORE"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:18.677245Z",
     "start_time": "2024-08-23T18:02:18.669706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_input = dspy.Example()"
   ],
   "id": "a4319ae8323cd4de",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 1: Conciseness"
   ],
   "id": "403a161d8d30b1cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:18.707907Z",
     "start_time": "2024-08-23T18:02:18.695623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "short_output = dspy.Prediction(narrative='word ')\n",
    "short_result = metrics.conciseness(empty_input, short_output, max_optimal_length=10)\n",
    "assert short_result == max_score, short_result\n",
    "\n",
    "long_output = dspy.Prediction(narrative='word ' * 21)\n",
    "long_result = metrics.conciseness(empty_input, long_output, max_optimal_length=10)\n",
    "assert long_result == 0, long_result\n",
    "\n",
    "med_output = dspy.Prediction(narrative='word ' * 15)\n",
    "med_result = metrics.conciseness(empty_input, med_output, max_optimal_length=10)\n",
    "assert med_result == max_score / 2, med_result"
   ],
   "id": "9cb6db83bfc4843e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 2: Accuracy"
   ],
   "id": "79045feb8d8af121"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:18.738430Z",
     "start_time": "2024-08-23T18:02:18.719533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "accurate_result = metrics.accuracy(test_input, accurate_output, grader=grader)\n",
    "assert accurate_result == max_score, accurate_result\n",
    "\n",
    "inaccurate_output = dspy.Prediction(narrative='The size being 4 increased the prediction by 11. The color being red decreased the prediction by 9.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "incomplete_but_accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10.')\n",
    "incomplete_but_accurate_result = metrics.accuracy(test_input, incomplete_but_accurate_output, grader=grader)\n",
    "assert incomplete_but_accurate_result == max_score, incomplete_but_accurate_result"
   ],
   "id": "14168fb360045bcc",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 3: Completeness"
   ],
   "id": "583c04d26f9b3e7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:18.754104Z",
     "start_time": "2024-08-23T18:02:18.740930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8), (Shape, Square, 3)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "complete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8. The shape being square increased the prediction by 3.')\n",
    "complete_result = metrics.completeness(test_input, complete_output, grader)\n",
    "assert complete_result == max_score, complete_result\n",
    "\n",
    "incomplete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "incomplete_result = metrics.completeness(test_input, incomplete_output, grader)\n",
    "assert incomplete_result == 0, incomplete_result"
   ],
   "id": "23379cf2fdd4aa59",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:18.924216Z",
     "start_time": "2024-08-23T18:02:18.755992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "completeness_dataset = json.load(open(\"completeness_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "for example in completeness_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.completeness(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"completeness_score\"])\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 2.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 2.0, 4.0])\n",
    "disp.plot()"
   ],
   "id": "ccb29b25ae81c281",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1ac464ac3d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 4: Fluency\n",
    "\n",
    "We test fluency with two methods:\n",
    "1. A few basic unit tests\n",
    "2. Ensuring that fluency consistently scores higher on whatever dataset is labeled gold standard dataset than on other datasets"
   ],
   "id": "f513c89283bc9ed5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:19.001406Z",
     "start_time": "2024-08-23T18:02:18.926213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "good_narratives = ['The large size increased the prediction by 100, while the green color decreased it by about 20',\n",
    "                   \"The item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\"]\n",
    "\n",
    "fluent_output = dspy.Prediction(narrative='The large size of the item increased the prediction by about 10, while the red color decreased it by 8.')\n",
    "fluent_result = metrics.fluency(empty_input, fluent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "influent_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10.5. The color being red decreased it by 8.2')\n",
    "influent_result = metrics.fluency(empty_input, influent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "assert influent_result < fluent_result\n",
    "assert fluent_result == max_score, fluent_result\n",
    "\n",
    "very_influent_output = dspy.Prediction(narrative='Size 5 10.5 color red')\n",
    "very_influent_result = metrics.fluency(empty_input, very_influent_output, grader, good_narratives=good_narratives)\n",
    "assert very_influent_result == 0, very_influent_result"
   ],
   "id": "2214a9f493150063",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "metric_verification_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "labeled_train, labeled_eval, unlabeled_train, unlabeled_eval = examples.get_data(\"gold_standards.json\")\n",
    "train_data = labeled_train + unlabeled_train\n",
    "eval_data = labeled_eval + unlabeled_eval\n",
    "max_optimal_length = max([len(d.narrative) for d in labeled_train])\n",
    "\n",
    "example_good_narratives = random.sample([d.narrative for d in labeled_train], 5)\n",
    "example_bad_narratives = random.sample([d.bad_narrative for d in labeled_train if hasattr(d, \"bad_narrative\")], 5)\n",
    "\n",
    "# Example datasets do not include a rationalization, so we skip context awareness \n",
    "ver_metrics = metrics.Metrics(\n",
    "    [\n",
    "        metrics.accuracy,\n",
    "        metrics.fluency,\n",
    "        metrics.conciseness,\n",
    "        #metrics.completeness\n",
    "    ], verbose=0, openai_key=openai_api_key,\n",
    "    metric_kwargs={\"conciseness\": {\"max_optimal_length\": max_optimal_length},\n",
    "                   \"fluency\": {\"good_narratives\": example_good_narratives, \"bad_narratives\": example_bad_narratives}}\n",
    ")\n",
    "\n",
    "for dataset in metric_verification_datasets: \n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    all_results = None\n",
    "    score = 0\n",
    "    for example in labeled_train:\n",
    "        result = ver_metrics(example, example)\n",
    "        score += result[0]\n",
    "        if all_results is None:\n",
    "            all_results = result[1]\n",
    "        else:\n",
    "            all_results += result[1]\n",
    "    print(f\"Dataset: {dataset}, Average score: {score/len(labeled_train)}/{len(ver_metrics.metric_funcs)*4.0}\")\n",
    "    print(all_results/len(labeled_train))"
   ],
   "id": "605caeedebe5ccc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 5: Context-Awareness"
   ],
   "id": "c3bfd9e3b5c0bbfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:02:19.064360Z",
     "start_time": "2024-08-23T18:02:19.002402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "context_aware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.',\n",
    "                                       rationalization='Large items fit more contents, making them desirable, so they increase the price. People associate red with the devil, so this color decreases the price.')\n",
    "context_aware_result = metrics.context_awareness(test_input, context_aware_output, grader)\n",
    "assert context_aware_result >= max_score/2, context_aware_result\n",
    "\n",
    "context_unaware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.', \n",
    "                                         rationalization='No idea why.')\n",
    "context_unaware_result = metrics.context_awareness(test_input, context_unaware_output, grader)\n",
    "assert context_unaware_result == 0, context_unaware_result"
   ],
   "id": "8375bcc0043ea6ee",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Compare Datasets\n",
    "\n",
    "In the following code block, we verify our metric functionality by comparing average score on our gold standard dataset (used to tune the metrics) to other datasets that use different styles of explanations. We expect the gold standard average score to be very close to 2*len(metrics) (since each metric is scored on a scale of 0-2), and the other datasets to be lower.\n",
    " \n",
    "TODO: We do not currently verify the context awareness metric, as the gold-standard dataset does not include a rationalization"
   ],
   "id": "ff5cda333b3fc86f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gold_standards.json, Average score: 11.85/12.0\n",
      "accuracy       4.00\n",
      "fluency        3.85\n",
      "conciseness    4.00\n",
      "dtype: float64\n",
      "Dataset: unaligned_examples_1.json, Average score: 11.25/12.0\n",
      "accuracy       4.00\n",
      "fluency        3.25\n",
      "conciseness    4.00\n",
      "dtype: float64\n",
      "Dataset: unaligned_examples_2.json, Average score: 11.11111111111111/12.0\n",
      "accuracy       4.000000\n",
      "fluency        3.111111\n",
      "conciseness    4.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 26,
   "source": [
    "metric_verification_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "labeled_train, labeled_eval, unlabeled_train, unlabeled_eval = examples.get_data(\"gold_standards.json\")\n",
    "train_data = labeled_train + unlabeled_train\n",
    "eval_data = labeled_eval + unlabeled_eval\n",
    "max_optimal_length = max([len(d.narrative) for d in labeled_train])\n",
    "\n",
    "example_good_narratives = random.sample([d.narrative for d in labeled_train], 5)\n",
    "example_bad_narratives = random.sample([d.bad_narrative for d in labeled_train if hasattr(d, \"bad_narrative\")], 5)\n",
    "\n",
    "# Example datasets do not include a rationalization, so we skip context awareness \n",
    "ver_metrics = metrics.Metrics(\n",
    "    [\n",
    "        metrics.accuracy,\n",
    "        metrics.fluency,\n",
    "        metrics.conciseness,\n",
    "        #metrics.completeness\n",
    "    ], verbose=0, openai_key=openai_api_key,\n",
    "    metric_kwargs={\"conciseness\": {\"max_optimal_length\": max_optimal_length},\n",
    "                   \"fluency\": {\"good_narratives\": example_good_narratives, \"bad_narratives\": example_bad_narratives}}\n",
    ")\n",
    "\n",
    "for dataset in metric_verification_datasets: \n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    all_results = None\n",
    "    score = 0\n",
    "    for example in labeled_train:\n",
    "        result = ver_metrics(example, example)\n",
    "        score += result[0]\n",
    "        if all_results is None:\n",
    "            all_results = result[1]\n",
    "        else:\n",
    "            all_results += result[1]\n",
    "    print(f\"Dataset: {dataset}, Average score: {score/len(labeled_train)}/{len(ver_metrics.metric_funcs)*4.0}\")\n",
    "    print(all_results/len(labeled_train))"
   ],
   "id": "7b59478832886fed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Failing Cases"
   ],
   "id": "cc5f59cef2f2ca2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:03:05.478470Z",
     "start_time": "2024-08-23T18:03:04.840024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inaccurate_output = dspy.Prediction(narrative='The size being 5 decreased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "misleading_output = dspy.Prediction(narrative='Surprisingly, the large house size of 5 increased the predicted price')\n",
    "misleading_result = metrics.accuracy(test_input, misleading_output, grader=grader)\n",
    "assert 0 < misleading_result < 4, misleading_result"
   ],
   "id": "761fe0aa9fc2f680",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "4.0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m misleading_output \u001B[38;5;241m=\u001B[39m dspy\u001B[38;5;241m.\u001B[39mPrediction(narrative\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSurprisingly, the large house size of 5 increased the predicted price\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m misleading_result \u001B[38;5;241m=\u001B[39m metrics\u001B[38;5;241m.\u001B[39maccuracy(test_input, misleading_output, grader\u001B[38;5;241m=\u001B[39mgrader)\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;241m<\u001B[39m misleading_result \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m4\u001B[39m, misleading_result\n",
      "\u001B[1;31mAssertionError\u001B[0m: 4.0"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "5c9ab560813b91c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
