{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:10:15.695380Z",
     "start_time": "2024-08-31T14:10:12.693342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import metrics\n",
    "import dspy\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "import examples\n",
    "\n",
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "    \n",
    "grader = dspy.OpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            model_type=\"chat\",\n",
    "            max_tokens=500,\n",
    "            api_key=openai_api_key,\n",
    "            temperature=0.3,\n",
    "        )\n",
    "    \n",
    "os.environ[\"DSP_CACHEBOOL\"] = \"False\"\n",
    "\n",
    "max_score = metrics.MAX_SCORE"
   ],
   "id": "d5efeb7510b98046",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:10:15.711069Z",
     "start_time": "2024-08-31T14:10:15.698067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_input = dspy.Example()"
   ],
   "id": "d57e310a4b23ed8f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 1: Conciseness"
   ],
   "id": "a98751c87bdae1f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:17:06.093210Z",
     "start_time": "2024-08-31T14:17:06.083868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "short_output = dspy.Prediction(narrative='word ', explanation='(word, .05, .05)')\n",
    "short_result = metrics.conciseness(empty_input, short_output, max_optimal_length_per_feature=10)\n",
    "assert short_result == max_score, short_result\n",
    "\n",
    "long_output = dspy.Prediction(narrative='word ' * 21, explanation='(word, .05, .05)')\n",
    "long_result = metrics.conciseness(empty_input, long_output, max_optimal_length_per_feature=10)\n",
    "assert long_result == 0, long_result\n",
    "\n",
    "med_output = dspy.Prediction(narrative='word ' * 15, explanation='(word, .05, .05)')\n",
    "med_result = metrics.conciseness(empty_input, med_output, max_optimal_length_per_feature=10)\n",
    "assert med_result == max_score / 2, med_result\n",
    "\n",
    "two_word_output = dspy.Prediction(narrative='word ' * 18, explanation='(word, .05, .05), (word, .05, .05)')\n",
    "two_word_result = metrics.conciseness(empty_input, two_word_output, max_optimal_length_per_feature=10)\n",
    "assert two_word_result == max_score, two_word_result\n",
    "\n",
    "two_word_output = dspy.Prediction(narrative='word ' * 30, explanation='(word, .05, .05), (word, .05, .05)')\n",
    "two_word_result = metrics.conciseness(empty_input, two_word_output, max_optimal_length_per_feature=10)\n",
    "assert two_word_result == max_score / 2, two_word_result"
   ],
   "id": "73a06bbd8dab9e9e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 2: Accuracy"
   ],
   "id": "57d5cb5147ddac36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "accurate_result = metrics.accuracy(test_input, accurate_output, grader=grader)\n",
    "assert accurate_result == max_score, accurate_result\n",
    "\n",
    "inaccurate_output = dspy.Prediction(narrative='The size being 4 increased the prediction by 11. The color being red decreased the prediction by 9.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "incomplete_but_accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10.')\n",
    "incomplete_but_accurate_result = metrics.accuracy(test_input, incomplete_but_accurate_output, grader=grader)\n",
    "assert incomplete_but_accurate_result == max_score, incomplete_but_accurate_result"
   ],
   "id": "5325ca464e28753e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grader.inspect_history(n=1)"
   ],
   "id": "9d97955cc0f6b915",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:09:18.641952Z",
     "start_time": "2024-08-31T14:09:18.637952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy_dataset = json.load(open(\"accuracy_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "for example in accuracy_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.accuracy(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"accuracy_score\"])\n",
    "    if result != example[\"accuracy_score\"]:\n",
    "        print(f'Explanation: {example[\"explanation\"]}')\n",
    "        print(f'Output: {example[\"narrative\"]}')\n",
    "        print(f'Expected: {example[\"accuracy_score\"]}. Got: {result}')\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 4.0])\n",
    "disp.plot()"
   ],
   "id": "68720a6634ec642e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 3: Completeness"
   ],
   "id": "583c04d26f9b3e7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:09:18.806215Z",
     "start_time": "2024-08-31T14:09:18.654103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8), (Shape, Square, 3)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "complete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8. The shape being square increased the prediction by 3.')\n",
    "complete_result = metrics.completeness(test_input, complete_output, grader)\n",
    "assert complete_result == max_score, complete_result\n",
    "\n",
    "incomplete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10')\n",
    "incomplete_result = metrics.completeness(test_input, incomplete_output, grader)\n",
    "assert incomplete_result == 0, incomplete_result"
   ],
   "id": "23379cf2fdd4aa59",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:09:25.191836Z",
     "start_time": "2024-08-31T14:09:18.817216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "completeness_dataset = json.load(open(\"completeness_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "rationalization_when_failing = defaultdict(int)\n",
    "for example in completeness_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.completeness(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"completeness_score\"])\n",
    "    if result != example[\"completeness_score\"]:\n",
    "        print(f'Explanation: {example[\"explanation\"]}')\n",
    "        print(f'Output: {example[\"narrative\"]}')\n",
    "        print(f'Expected: {example[\"completeness_score\"]}. Got: {result}')\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 2.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 2.0, 4.0])\n",
    "disp.plot()"
   ],
   "id": "45e2591357b25792",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: (Type 1 finished square feet, 1369.00, 14641.53), (Evaluates the height of the basement, Ex, 13233.24), (Total square feet of basement area, 1686.00, 12138.28), (Second floor square feet, 0.00, -10142.29), (Rates the overall material and finish of the house, 8.00, 9655.79)\n",
      "Output: This house's relatively large type 1 finished square footage increased the predicted price by about $14,000. The house's excellent basement height increased the price by about $13,000. The relatively larger basement area increased the price by about $12,000. The absence of a second floor reduced the price by about $10,000. The house's good condition (rated 8/10) increased the price by about $10,000.\n",
      "Expected: 2. Got: 4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x204ffdf6e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:09:25.255252Z",
     "start_time": "2024-08-31T14:09:25.198945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grader.inspect_history(n=1)"
   ],
   "id": "e7139317c1519015",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Assess a narrative based on a rubric.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Narrative: ${narrative}\n",
      "\n",
      "Rubric: ${rubric}\n",
      "\n",
      "Start by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Feature-by-feature processing of the narrative.\n",
      "\n",
      "Assessment: A single number from the options in the rubric. Provide only a single number with no other text.\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "How completely does the narrative below describe the explanation given in <<>>?\n",
      "Explanation format: SHAP feature contribution in (feature_name, feature_value, contribution) format.\n",
      "Explanation: <<(Number of past class failures, 0.00, 0.89), (Wants to take higher education, yes, 0.50), (Amount of free time after school (1-5), 4.00, -0.35), (School, GP, 0.33)>>\n",
      "\n",
      "Narrative: The student's lack of past class failures and desire for higher education significantly increase the predicted grade. However, the student's free time after school (rated 4/5) and school (GP) reputation slightly decrease the predicted grade.\n",
      "\n",
      "Rubric: 0 - One or more feature names from the explanation are not mentioned at all in the narrative. 2 - All features are mentioned, but not all feature values and/or contribution directions. 4 - All features are mentioned, and for each feature, includes at least an approximation of the feature's value and contribution direction.\n",
      "\n",
      "Start by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Features in the explanation:\n",
      "1. Number of past class failures (0.00, 0.89)\n",
      "2. Wants to take higher education (yes, 0.50)\n",
      "3. Amount of free time after school (1-5) (4.00, -0.35)\n",
      "4. School (GP, 0.33)\n",
      "\n",
      "Feature-by-feature processing of the narrative:\n",
      "1. Number of past class failures:\n",
      "   - Present in the narrative: \"The student's lack of past class failures\"\n",
      "   - Value: \"lack of\" corresponds to 0.00\n",
      "   - Contribution direction: \"significantly increase\" corresponds to 0.89\n",
      "\n",
      "2. Wants to take higher education:\n",
      "   - Present in the narrative: \"desire for higher education\"\n",
      "   - Value: \"desire for\" corresponds to yes\n",
      "   - Contribution direction: \"significantly increase\" corresponds to 0.50\n",
      "\n",
      "3. Amount of free time after school (1-5):\n",
      "   - Present in the narrative: \"free time after school (rated 4/5)\"\n",
      "   - Value: \"rated 4/5\" corresponds to 4.00\n",
      "   - Contribution direction: \"slightly decrease\" corresponds to -0.35\n",
      "\n",
      "4. School:\n",
      "   - Present in the narrative: \"school (GP)\"\n",
      "   - Value: \"GP\" corresponds to GP\n",
      "   - Contribution direction: \"slightly decrease\" corresponds to 0.33\n",
      "\n",
      "Assessment: 4\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nAssess a narrative based on a rubric.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nNarrative: ${narrative}\\n\\nRubric: ${rubric}\\n\\nStart by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Feature-by-feature processing of the narrative.\\n\\nAssessment: A single number from the options in the rubric. Provide only a single number with no other text.\\n\\n---\\n\\nQuestion:\\nHow completely does the narrative below describe the explanation given in <<>>?\\nExplanation format: SHAP feature contribution in (feature_name, feature_value, contribution) format.\\nExplanation: <<(Number of past class failures, 0.00, 0.89), (Wants to take higher education, yes, 0.50), (Amount of free time after school (1-5), 4.00, -0.35), (School, GP, 0.33)>>\\n\\nNarrative: The student\\'s lack of past class failures and desire for higher education significantly increase the predicted grade. However, the student\\'s free time after school (rated 4/5) and school (GP) reputation slightly decrease the predicted grade.\\n\\nRubric: 0 - One or more feature names from the explanation are not mentioned at all in the narrative. 2 - All features are mentioned, but not all feature values and/or contribution directions. 4 - All features are mentioned, and for each feature, includes at least an approximation of the feature\\'s value and contribution direction.\\n\\nStart by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction.\\x1b[32m Features in the explanation:\\n1. Number of past class failures (0.00, 0.89)\\n2. Wants to take higher education (yes, 0.50)\\n3. Amount of free time after school (1-5) (4.00, -0.35)\\n4. School (GP, 0.33)\\n\\nFeature-by-feature processing of the narrative:\\n1. Number of past class failures:\\n   - Present in the narrative: \"The student\\'s lack of past class failures\"\\n   - Value: \"lack of\" corresponds to 0.00\\n   - Contribution direction: \"significantly increase\" corresponds to 0.89\\n\\n2. Wants to take higher education:\\n   - Present in the narrative: \"desire for higher education\"\\n   - Value: \"desire for\" corresponds to yes\\n   - Contribution direction: \"significantly increase\" corresponds to 0.50\\n\\n3. Amount of free time after school (1-5):\\n   - Present in the narrative: \"free time after school (rated 4/5)\"\\n   - Value: \"rated 4/5\" corresponds to 4.00\\n   - Contribution direction: \"slightly decrease\" corresponds to -0.35\\n\\n4. School:\\n   - Present in the narrative: \"school (GP)\"\\n   - Value: \"GP\" corresponds to GP\\n   - Contribution direction: \"slightly decrease\" corresponds to 0.33\\n\\nAssessment: 4\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 4: Fluency\n",
    "\n",
    "We test fluency with two methods:\n",
    "1. A few basic unit tests\n",
    "2. Ensuring that fluency consistently scores higher on whatever dataset is labeled gold standard dataset than on other datasets"
   ],
   "id": "f513c89283bc9ed5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:09:25.365361Z",
     "start_time": "2024-08-31T14:09:25.276638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "good_narratives = ['The large size increased the prediction by 100, while the green color decreased it by about 20',\n",
    "                   \"The item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\"]\n",
    "\n",
    "fluent_output = dspy.Prediction(narrative='The large size increased the prediction by about 10, while the red color decreased it by 8.')\n",
    "fluent_result = metrics.fluency(empty_input, fluent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "influent_output = dspy.Prediction(narrative='The size (5) increased the prediction (10.5). The color (red) decreased it (8.2)')\n",
    "influent_result = metrics.fluency(empty_input, influent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "assert influent_result < fluent_result, str(influent_result) + \" \" + str(fluent_result)\n",
    "assert fluent_result == max_score, fluent_result\n",
    "\n",
    "very_influent_output = dspy.Prediction(narrative='Size 5 10.5 color red')\n",
    "very_influent_result = metrics.fluency(empty_input, very_influent_output, grader, good_narratives=good_narratives)\n",
    "assert very_influent_result == 0, very_influent_result"
   ],
   "id": "2214a9f493150063",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:09:25.380632Z",
     "start_time": "2024-08-31T14:09:25.367257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grader.inspect_history(n=1)"
   ],
   "id": "bb99a245f13d0356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Assess a narrative based on a rubric.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Narrative: ${narrative}\n",
      "\n",
      "Rubric: ${rubric}\n",
      "\n",
      "Assessment: A single number from the options in the rubric. Provide only a single number with no other text.\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "How well does the style of the narrative match the style of these examples:\n",
      "The large size increased the prediction by 100, while the green color decreased it by about 20\n",
      "The item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\n",
      "\n",
      "Narrative: Size 5 10.5 color red\n",
      "\n",
      "Rubric: 0: Very dissimilar. 1: Dissimilar. 2: Neutral. 3: Similar. 4: Very similar\n",
      "\n",
      "Assessment: 0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nAssess a narrative based on a rubric.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nNarrative: ${narrative}\\n\\nRubric: ${rubric}\\n\\nAssessment: A single number from the options in the rubric. Provide only a single number with no other text.\\n\\n---\\n\\nQuestion:\\nHow well does the style of the narrative match the style of these examples:\\nThe large size increased the prediction by 100, while the green color decreased it by about 20\\nThe item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\\n\\nNarrative: Size 5 10.5 color red\\n\\nRubric: 0: Very dissimilar. 1: Dissimilar. 2: Neutral. 3: Similar. 4: Very similar\\n\\nAssessment:\\x1b[32m 0\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-31T14:09:25.382641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get all files in eval_data\n",
    "validation_datasets = [f for f in os.listdir(\"eval_data\") if os.path.isfile(os.path.join(\"eval_data\", f))]\n",
    "\n",
    "loaded_datasets = {}\n",
    "for dataset in validation_datasets:\n",
    "    labeled_train, _, _, _ = examples.get_data(os.path.join(\"eval_data\", dataset), split=1)\n",
    "    loaded_datasets[dataset] = labeled_train\n",
    "\n",
    "def validate_fluency(gold_standard_dataset):\n",
    "    example_good_narratives = random.sample([d.narrative for d in loaded_datasets[gold_standard_dataset]], 5)\n",
    "    all_results = {}\n",
    "    for dataset in loaded_datasets:\n",
    "        all_results[dataset] = 0\n",
    "        for example in loaded_datasets[dataset]:\n",
    "            all_results[dataset] += metrics.fluency(empty_input, example, grader, good_narratives=example_good_narratives)\n",
    "        all_results[dataset] /= len(loaded_datasets[dataset])\n",
    "    print(f\"Gold standard: {gold_standard_dataset}\")\n",
    "    for dataset in all_results:\n",
    "        if dataset == gold_standard_dataset:\n",
    "            print(f\"**Dataset: {dataset}, Average score: {all_results[dataset]:.2f}\")\n",
    "        else:\n",
    "            print(f\"--Dataset: {dataset}, Average score: {all_results[dataset]:.2f}\")\n",
    "    print()\n",
    "    \n",
    "for dataset in loaded_datasets:\n",
    "    validate_fluency(dataset)"
   ],
   "id": "605caeedebe5ccc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 5: Context-Awareness"
   ],
   "id": "c3bfd9e3b5c0bbfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "context_aware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.',\n",
    "                                       rationalization='Large items fit more contents, making them desirable, so they increase the price. People associate red with the devil, so this color decreases the price.')\n",
    "context_aware_result = metrics.context_awareness(test_input, context_aware_output, grader)\n",
    "assert context_aware_result >= max_score/2, context_aware_result\n",
    "\n",
    "context_unaware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.', \n",
    "                                         rationalization='No idea why.')\n",
    "context_unaware_result = metrics.context_awareness(test_input, context_unaware_output, grader)\n",
    "assert context_unaware_result == 0, context_unaware_result"
   ],
   "id": "8375bcc0043ea6ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Compare Datasets\n",
    "\n",
    "In the following code block, we verify our metric functionality by comparing average score on our gold standard dataset (used to tune the metrics) to other datasets that use different styles of explanations. We expect the gold standard average score to be very close to 2*len(metrics) (since each metric is scored on a scale of 0-2), and the other datasets to be lower.\n",
    " \n",
    "TODO: We do not currently verify the context awareness metric, as the gold-standard dataset does not include a rationalization"
   ],
   "id": "ff5cda333b3fc86f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metric_verification_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "labeled_train, labeled_eval, unlabeled_train, unlabeled_eval = examples.get_data(\"gold_standards.json\")\n",
    "train_data = labeled_train + unlabeled_train\n",
    "eval_data = labeled_eval + unlabeled_eval\n",
    "max_optimal_length = max([len(d.narrative) for d in labeled_train])\n",
    "\n",
    "example_good_narratives = random.sample([d.narrative for d in labeled_train], 5)\n",
    "example_bad_narratives = random.sample([d.bad_narrative for d in labeled_train if hasattr(d, \"bad_narrative\")], 5)\n",
    "\n",
    "# Example datasets do not include a rationalization, so we skip context awareness \n",
    "ver_metrics = metrics.Metrics(\n",
    "    [\n",
    "        metrics.accuracy,\n",
    "        metrics.fluency,\n",
    "        metrics.conciseness,\n",
    "        #metrics.completeness\n",
    "    ], verbose=0, openai_key=openai_api_key,\n",
    "    metric_kwargs={\"conciseness\": {\"max_optimal_length\": max_optimal_length},\n",
    "                   \"fluency\": {\"good_narratives\": example_good_narratives, \"bad_narratives\": example_bad_narratives}}\n",
    ")\n",
    "\n",
    "for dataset in metric_verification_datasets: \n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    all_results = None\n",
    "    score = 0\n",
    "    for example in labeled_train:\n",
    "        result = ver_metrics(example, example)\n",
    "        score += result[0]\n",
    "        if all_results is None:\n",
    "            all_results = result[1]\n",
    "        else:\n",
    "            all_results += result[1]\n",
    "    print(f\"Dataset: {dataset}, Average score: {score/len(labeled_train)}/{len(ver_metrics.metric_funcs)*4.0}\")\n",
    "    print(all_results/len(labeled_train))"
   ],
   "id": "7b59478832886fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Failing Cases"
   ],
   "id": "cc5f59cef2f2ca2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inaccurate_output = dspy.Prediction(narrative='The size being 5 decreased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "misleading_output = dspy.Prediction(narrative='Surprisingly, the large house size of 5 increased the predicted price')\n",
    "misleading_result = metrics.accuracy(test_input, misleading_output, grader=grader)\n",
    "assert 0 < misleading_result < 4, misleading_result"
   ],
   "id": "761fe0aa9fc2f680",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "5c9ab560813b91c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
