{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:29:18.762135Z",
     "start_time": "2024-08-31T14:29:15.394779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import metrics\n",
    "import dspy\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "import examples\n",
    "\n",
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "    \n",
    "grader = dspy.OpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            model_type=\"chat\",\n",
    "            max_tokens=500,\n",
    "            api_key=openai_api_key,\n",
    "            temperature=0.3,\n",
    "        )\n",
    "    \n",
    "os.environ[\"DSP_CACHEBOOL\"] = \"False\"\n",
    "\n",
    "max_score = metrics.MAX_SCORE"
   ],
   "id": "d5efeb7510b98046",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:19.214109Z",
     "start_time": "2024-08-31T14:24:19.176116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_input = dspy.Example()"
   ],
   "id": "d57e310a4b23ed8f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 1: Conciseness"
   ],
   "id": "a98751c87bdae1f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:19.230009Z",
     "start_time": "2024-08-31T14:24:19.218005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "one_feature_input = dspy.Example(explanation='(word, .05, .05)')\n",
    "two_feature_input = dspy.Example(explanation='(word, .05, .05), (word, .05, .05)')\n",
    "\n",
    "short_output = dspy.Prediction(narrative='word ')\n",
    "short_result = metrics.conciseness(one_feature_input, short_output, max_optimal_length_per_feature=10)\n",
    "assert short_result == max_score, short_result\n",
    "\n",
    "long_output = dspy.Prediction(narrative='word ' * 21)\n",
    "long_result = metrics.conciseness(one_feature_input, long_output, max_optimal_length_per_feature=10)\n",
    "assert long_result == 0, long_result\n",
    "\n",
    "med_output = dspy.Prediction(narrative='word ' * 15)\n",
    "med_result = metrics.conciseness(one_feature_input, med_output, max_optimal_length_per_feature=10)\n",
    "assert med_result == max_score / 2, med_result\n",
    "\n",
    "two_word_output = dspy.Prediction(narrative='word ' * 18)\n",
    "two_word_result = metrics.conciseness(two_feature_input, two_word_output, max_optimal_length_per_feature=10)\n",
    "assert two_word_result == max_score, two_word_result\n",
    "\n",
    "two_word_output = dspy.Prediction(narrative='word ' * 30)\n",
    "two_word_result = metrics.conciseness(two_feature_input, two_word_output, max_optimal_length_per_feature=10)\n",
    "assert two_word_result == max_score / 2, two_word_result"
   ],
   "id": "73a06bbd8dab9e9e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 2: Accuracy"
   ],
   "id": "57d5cb5147ddac36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:19.340368Z",
     "start_time": "2024-08-31T14:24:19.233004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "accurate_result = metrics.accuracy(test_input, accurate_output, grader=grader)\n",
    "assert accurate_result == max_score, accurate_result\n",
    "\n",
    "inaccurate_output = dspy.Prediction(narrative='The size being 4 increased the prediction by 11. The color being red decreased the prediction by 9.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "incomplete_but_accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10.')\n",
    "incomplete_but_accurate_result = metrics.accuracy(test_input, incomplete_but_accurate_output, grader=grader)\n",
    "assert incomplete_but_accurate_result == max_score, incomplete_but_accurate_result"
   ],
   "id": "5325ca464e28753e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:19.371136Z",
     "start_time": "2024-08-31T14:24:19.343386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grader.inspect_history(n=1)"
   ],
   "id": "9d97955cc0f6b915",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Assess a narrative based on a rubric.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Narrative: ${narrative}\n",
      "\n",
      "Rubric: ${rubric}\n",
      "\n",
      "Assessment: A single number from the options in the rubric. Provide only a single number with no other text.\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "How accurate is the information in the narrative, based on the explanation given? A narrative can score 4 even if it is missing information as long as everything in the narrative is correct. Make sure the contribution direction is correct - positive contributions increase the output, negative contributions decrease the output.\n",
      "\n",
      "Explanation format: (feature_name, feature_value, SHAP contribution).\n",
      "Explanation: (Size, 5, 10), (Color, Red, -8)\n",
      "\n",
      "Narrative: The size being 5 increased the prediction by 10.\n",
      "\n",
      "Rubric: 0 - Contains one or more errors in value or contribution direction. 4 - Contains no errors, but may be missing information.\n",
      "\n",
      "Assessment: 4\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nAssess a narrative based on a rubric.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nNarrative: ${narrative}\\n\\nRubric: ${rubric}\\n\\nAssessment: A single number from the options in the rubric. Provide only a single number with no other text.\\n\\n---\\n\\nQuestion:\\nHow accurate is the information in the narrative, based on the explanation given? A narrative can score 4 even if it is missing information as long as everything in the narrative is correct. Make sure the contribution direction is correct - positive contributions increase the output, negative contributions decrease the output.\\n\\nExplanation format: (feature_name, feature_value, SHAP contribution).\\nExplanation: (Size, 5, 10), (Color, Red, -8)\\n\\nNarrative: The size being 5 increased the prediction by 10.\\n\\nRubric: 0 - Contains one or more errors in value or contribution direction. 4 - Contains no errors, but may be missing information.\\n\\nAssessment:\\x1b[32m 4\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:20.963811Z",
     "start_time": "2024-08-31T14:24:19.374124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy_dataset = json.load(open(\"accuracy_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "for example in accuracy_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.accuracy(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"accuracy_score\"])\n",
    "    if result != example[\"accuracy_score\"]:\n",
    "        print(f'Explanation: {example[\"explanation\"]}')\n",
    "        print(f'Output: {example[\"narrative\"]}')\n",
    "        print(f'Expected: {example[\"accuracy_score\"]}. Got: {result}')\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 4.0])\n",
    "disp.plot()"
   ],
   "id": "68720a6634ec642e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: (odor, foul, 0.15), (gill-size, narrow, 0.11), (gill-color, buff, 0.08)\n",
      "Output: The foul odor increases the model's prediction by 2.5, and the narrow gill size and buff color also increase the prediction.\n",
      "Expected: 0. Got: 4.0\n",
      "Explanation: (Quality of materials out of 10, 3, 560.46), (Size in sq ft, 1020, 909)\n",
      "Output: The house's quality of 3/10 increased the model's prediction by around 500, while its size of around 1000 sq ft increased it by about 900\n",
      "Expected: 4. Got: 0.0\n",
      "Explanation: (Number of streams, 1.00, 0.10), (Number of objects, 1.00, 0.10)\n",
      "Output: The file's number of streams increases the model's prediction by 10\n",
      "Expected: 0. Got: 4.0\n",
      "Explanation: (In a romantic relationship, yes, -2.00), (Family educational support, yes, 2.00), (Absences, high, -4.00)\n",
      "Output: Being in a romantic relationship decreases the student's likelihood of passing.\n",
      "Expected: 4. Got: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x232e7abc9a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 3: Completeness"
   ],
   "id": "583c04d26f9b3e7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:21.026533Z",
     "start_time": "2024-08-31T14:24:20.968909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8), (Shape, Square, 3)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "complete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8. The shape being square increased the prediction by 3.')\n",
    "complete_result = metrics.completeness(test_input, complete_output, grader)\n",
    "assert complete_result == max_score, complete_result\n",
    "\n",
    "incomplete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10')\n",
    "incomplete_result = metrics.completeness(test_input, incomplete_output, grader)\n",
    "assert incomplete_result == 0, incomplete_result"
   ],
   "id": "23379cf2fdd4aa59",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:21.611886Z",
     "start_time": "2024-08-31T14:24:21.029537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "completeness_dataset = json.load(open(\"completeness_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "rationalization_when_failing = defaultdict(int)\n",
    "for example in completeness_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.completeness(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"completeness_score\"])\n",
    "    if result != example[\"completeness_score\"]:\n",
    "        print(f'Explanation: {example[\"explanation\"]}')\n",
    "        print(f'Output: {example[\"narrative\"]}')\n",
    "        print(f'Expected: {example[\"completeness_score\"]}. Got: {result}')\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 2.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 2.0, 4.0])\n",
    "disp.plot()"
   ],
   "id": "45e2591357b25792",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: (Type 1 finished square feet, 1369.00, 14641.53), (Evaluates the height of the basement, Ex, 13233.24), (Total square feet of basement area, 1686.00, 12138.28), (Second floor square feet, 0.00, -10142.29), (Rates the overall material and finish of the house, 8.00, 9655.79)\n",
      "Output: This house's relatively large type 1 finished square footage increased the predicted price by about $14,000. The house's excellent basement height increased the price by about $13,000. The relatively larger basement area increased the price by about $12,000. The absence of a second floor reduced the price by about $10,000. The house's good condition (rated 8/10) increased the price by about $10,000.\n",
      "Expected: 2. Got: 4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x232e7ba4c40>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:21.673788Z",
     "start_time": "2024-08-31T14:24:21.618887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grader.inspect_history(n=1)"
   ],
   "id": "e7139317c1519015",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Assess a narrative based on a rubric.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Narrative: ${narrative}\n",
      "\n",
      "Rubric: ${rubric}\n",
      "\n",
      "Start by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Feature-by-feature processing of the narrative.\n",
      "\n",
      "Assessment: A single number from the options in the rubric. Provide only a single number with no other text.\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "How completely does the narrative below describe the explanation given in <<>>?\n",
      "Explanation format: SHAP feature contribution in (feature_name, feature_value, contribution) format.\n",
      "Explanation: <<(Number of past class failures, 0.00, 0.89), (Wants to take higher education, yes, 0.50), (Amount of free time after school (1-5), 4.00, -0.35), (School, GP, 0.33)>>\n",
      "\n",
      "Narrative: The student's lack of past class failures and desire for higher education significantly increase the predicted grade. However, the student's free time after school (rated 4/5) and school (GP) reputation slightly decrease the predicted grade.\n",
      "\n",
      "Rubric: 0 - One or more feature names from the explanation are not mentioned at all in the narrative. 2 - All features are mentioned, but not all feature values and/or contribution directions. 4 - All features are mentioned, and for each feature, includes at least an approximation of the feature's value and contribution direction.\n",
      "\n",
      "Start by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Features in the explanation:\n",
      "1. Number of past class failures (0.00, 0.89)\n",
      "2. Wants to take higher education (yes, 0.50)\n",
      "3. Amount of free time after school (1-5) (4.00, -0.35)\n",
      "4. School (GP, 0.33)\n",
      "\n",
      "Feature-by-feature processing of the narrative:\n",
      "1. Number of past class failures:\n",
      "   - Present in the narrative: \"The student's lack of past class failures\"\n",
      "   - Value: \"lack of\" corresponds to 0.00\n",
      "   - Contribution direction: \"significantly increase\" corresponds to 0.89\n",
      "\n",
      "2. Wants to take higher education:\n",
      "   - Present in the narrative: \"desire for higher education\"\n",
      "   - Value: \"desire for\" corresponds to yes\n",
      "   - Contribution direction: \"significantly increase\" corresponds to 0.50\n",
      "\n",
      "3. Amount of free time after school (1-5):\n",
      "   - Present in the narrative: \"free time after school (rated 4/5)\"\n",
      "   - Value: \"rated 4/5\" corresponds to 4.00\n",
      "   - Contribution direction: \"slightly decrease\" corresponds to -0.35\n",
      "\n",
      "4. School:\n",
      "   - Present in the narrative: \"school (GP)\"\n",
      "   - Value: \"GP\" corresponds to GP\n",
      "   - Contribution direction: \"slightly decrease\" corresponds to 0.33\n",
      "\n",
      "Assessment: 4\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nAssess a narrative based on a rubric.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nNarrative: ${narrative}\\n\\nRubric: ${rubric}\\n\\nStart by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Feature-by-feature processing of the narrative.\\n\\nAssessment: A single number from the options in the rubric. Provide only a single number with no other text.\\n\\n---\\n\\nQuestion:\\nHow completely does the narrative below describe the explanation given in <<>>?\\nExplanation format: SHAP feature contribution in (feature_name, feature_value, contribution) format.\\nExplanation: <<(Number of past class failures, 0.00, 0.89), (Wants to take higher education, yes, 0.50), (Amount of free time after school (1-5), 4.00, -0.35), (School, GP, 0.33)>>\\n\\nNarrative: The student\\'s lack of past class failures and desire for higher education significantly increase the predicted grade. However, the student\\'s free time after school (rated 4/5) and school (GP) reputation slightly decrease the predicted grade.\\n\\nRubric: 0 - One or more feature names from the explanation are not mentioned at all in the narrative. 2 - All features are mentioned, but not all feature values and/or contribution directions. 4 - All features are mentioned, and for each feature, includes at least an approximation of the feature\\'s value and contribution direction.\\n\\nStart by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction.\\x1b[32m Features in the explanation:\\n1. Number of past class failures (0.00, 0.89)\\n2. Wants to take higher education (yes, 0.50)\\n3. Amount of free time after school (1-5) (4.00, -0.35)\\n4. School (GP, 0.33)\\n\\nFeature-by-feature processing of the narrative:\\n1. Number of past class failures:\\n   - Present in the narrative: \"The student\\'s lack of past class failures\"\\n   - Value: \"lack of\" corresponds to 0.00\\n   - Contribution direction: \"significantly increase\" corresponds to 0.89\\n\\n2. Wants to take higher education:\\n   - Present in the narrative: \"desire for higher education\"\\n   - Value: \"desire for\" corresponds to yes\\n   - Contribution direction: \"significantly increase\" corresponds to 0.50\\n\\n3. Amount of free time after school (1-5):\\n   - Present in the narrative: \"free time after school (rated 4/5)\"\\n   - Value: \"rated 4/5\" corresponds to 4.00\\n   - Contribution direction: \"slightly decrease\" corresponds to -0.35\\n\\n4. School:\\n   - Present in the narrative: \"school (GP)\"\\n   - Value: \"GP\" corresponds to GP\\n   - Contribution direction: \"slightly decrease\" corresponds to 0.33\\n\\nAssessment: 4\\x1b[0m\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 4: Fluency\n",
    "\n",
    "We test fluency with two methods:\n",
    "1. A few basic unit tests\n",
    "2. Ensuring that fluency consistently scores higher on whatever dataset is labeled gold standard dataset than on other datasets"
   ],
   "id": "f513c89283bc9ed5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:21.705270Z",
     "start_time": "2024-08-31T14:24:21.676934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "good_narratives = ['The large size increased the prediction by 100, while the green color decreased it by about 20',\n",
    "                   \"The item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\"]\n",
    "\n",
    "fluent_output = dspy.Prediction(narrative='The large size increased the prediction by about 10, while the red color decreased it by 8.')\n",
    "fluent_result = metrics.fluency(empty_input, fluent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "influent_output = dspy.Prediction(narrative='The size (5) increased the prediction (10.5). The color (red) decreased it (8.2)')\n",
    "influent_result = metrics.fluency(empty_input, influent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "assert influent_result < fluent_result, str(influent_result) + \" \" + str(fluent_result)\n",
    "assert fluent_result == max_score, fluent_result\n",
    "\n",
    "very_influent_output = dspy.Prediction(narrative='Size 5 10.5 color red')\n",
    "very_influent_result = metrics.fluency(empty_input, very_influent_output, grader, good_narratives=good_narratives)\n",
    "assert very_influent_result == 0, very_influent_result"
   ],
   "id": "2214a9f493150063",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:21.721180Z",
     "start_time": "2024-08-31T14:24:21.709176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grader.inspect_history(n=1)"
   ],
   "id": "bb99a245f13d0356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Assess a narrative based on a rubric.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Narrative: ${narrative}\n",
      "\n",
      "Rubric: ${rubric}\n",
      "\n",
      "Assessment: A single number from the options in the rubric. Provide only a single number with no other text.\n",
      "\n",
      "---\n",
      "\n",
      "Question:\n",
      "How well does the style of the narrative match the style of these examples:\n",
      "The large size increased the prediction by 100, while the green color decreased it by about 20\n",
      "The item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\n",
      "\n",
      "Narrative: Size 5 10.5 color red\n",
      "\n",
      "Rubric: 0: Very dissimilar. 1: Dissimilar. 2: Neutral. 3: Similar. 4: Very similar\n",
      "\n",
      "Assessment: 0\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nAssess a narrative based on a rubric.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nNarrative: ${narrative}\\n\\nRubric: ${rubric}\\n\\nAssessment: A single number from the options in the rubric. Provide only a single number with no other text.\\n\\n---\\n\\nQuestion:\\nHow well does the style of the narrative match the style of these examples:\\nThe large size increased the prediction by 100, while the green color decreased it by about 20\\nThe item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\\n\\nNarrative: Size 5 10.5 color red\\n\\nRubric: 0: Very dissimilar. 1: Dissimilar. 2: Neutral. 3: Similar. 4: Very similar\\n\\nAssessment:\\x1b[32m 0\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:24:28.818369Z",
     "start_time": "2024-08-31T14:24:21.723459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get all files in eval_data\n",
    "validation_datasets = [f for f in os.listdir(\"eval_data\") if os.path.isfile(os.path.join(\"eval_data\", f))]\n",
    "\n",
    "loaded_datasets = {}\n",
    "for dataset in validation_datasets:\n",
    "    labeled_train, _, _, _ = examples.get_data(os.path.join(\"eval_data\", dataset), split=1)\n",
    "    loaded_datasets[dataset] = labeled_train\n",
    "\n",
    "def validate_fluency(gold_standard_dataset):\n",
    "    example_good_narratives = random.sample([d.narrative for d in loaded_datasets[gold_standard_dataset]], 5)\n",
    "    all_results = {}\n",
    "    for dataset in loaded_datasets:\n",
    "        all_results[dataset] = 0\n",
    "        for example in loaded_datasets[dataset]:\n",
    "            all_results[dataset] += metrics.fluency(empty_input, example, grader, good_narratives=example_good_narratives)\n",
    "        all_results[dataset] /= len(loaded_datasets[dataset])\n",
    "    print(f\"Gold standard: {gold_standard_dataset}\")\n",
    "    for dataset in all_results:\n",
    "        if dataset == gold_standard_dataset:\n",
    "            print(f\"**Dataset: {dataset}, Average score: {all_results[dataset]:.2f}\")\n",
    "        else:\n",
    "            print(f\"--Dataset: {dataset}, Average score: {all_results[dataset]:.2f}\")\n",
    "    print()\n",
    "    \n",
    "for dataset in loaded_datasets:\n",
    "    validate_fluency(dataset)"
   ],
   "id": "605caeedebe5ccc2",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 26\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28mprint\u001B[39m()\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m loaded_datasets:\n\u001B[1;32m---> 26\u001B[0m     \u001B[43mvalidate_fluency\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[12], line 15\u001B[0m, in \u001B[0;36mvalidate_fluency\u001B[1;34m(gold_standard_dataset)\u001B[0m\n\u001B[0;32m     13\u001B[0m     all_results[dataset] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m example \u001B[38;5;129;01min\u001B[39;00m loaded_datasets[dataset]:\n\u001B[1;32m---> 15\u001B[0m         all_results[dataset] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfluency\u001B[49m\u001B[43m(\u001B[49m\u001B[43mempty_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgood_narratives\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexample_good_narratives\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     all_results[dataset] \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(loaded_datasets[dataset])\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGold standard: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgold_standard_dataset\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\github\\Explingo\\full-experiment\\metrics.py:150\u001B[0m, in \u001B[0;36mfluency\u001B[1;34m(input_, output_, grader, trace, good_narratives, bad_narratives)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    147\u001B[0m     rubric \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    148\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0: Very unnatural. 1: Unnatural. 2: Neutral. 3: Natural. 4: Very natural\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    149\u001B[0m     )\n\u001B[1;32m--> 150\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompute_score_from_rubric\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfluency\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrubric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnarrative\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrader\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\github\\Explingo\\full-experiment\\metrics.py:102\u001B[0m, in \u001B[0;36mcompute_score_from_rubric\u001B[1;34m(metric, question, rubric, narrative, grader, iters, rational_type)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(iters):\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rational_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 102\u001B[0m         score \u001B[38;5;241m=\u001B[39m \u001B[43mdspy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mRubricAssess\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m            \u001B[49m\u001B[43mquestion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrubric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrubric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnarrative\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnarrative\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39massessment\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    106\u001B[0m         score \u001B[38;5;241m=\u001B[39m dspy\u001B[38;5;241m.\u001B[39mChainOfThought(RubricAssess, rationale_type\u001B[38;5;241m=\u001B[39mrational_type)(\n\u001B[0;32m    107\u001B[0m             question\u001B[38;5;241m=\u001B[39mquestion,\n\u001B[0;32m    108\u001B[0m             rubric\u001B[38;5;241m=\u001B[39mrubric,\n\u001B[0;32m    109\u001B[0m             narrative\u001B[38;5;241m=\u001B[39mnarrative,\n\u001B[0;32m    110\u001B[0m         )\u001B[38;5;241m.\u001B[39massessment\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dspy\\predict\\predict.py:78\u001B[0m, in \u001B[0;36mPredict.__call__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dspy\\predict\\predict.py:116\u001B[0m, in \u001B[0;36mPredict.forward\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    114\u001B[0m     completions \u001B[38;5;241m=\u001B[39m new_generate(lm, signature, dsp\u001B[38;5;241m.\u001B[39mExample(demos\u001B[38;5;241m=\u001B[39mdemos, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig)\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 116\u001B[0m     completions \u001B[38;5;241m=\u001B[39m \u001B[43mold_generate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdemos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msignature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m pred \u001B[38;5;241m=\u001B[39m Prediction\u001B[38;5;241m.\u001B[39mfrom_completions(completions, signature\u001B[38;5;241m=\u001B[39msignature)\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_trace\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m dsp\u001B[38;5;241m.\u001B[39msettings\u001B[38;5;241m.\u001B[39mtrace \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dspy\\predict\\predict.py:143\u001B[0m, in \u001B[0;36mold_generate\u001B[1;34m(demos, signature, kwargs, config, lm, stage)\u001B[0m\n\u001B[0;32m    140\u001B[0m template \u001B[38;5;241m=\u001B[39m signature_to_template(signature)\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 143\u001B[0m     x, C \u001B[38;5;241m=\u001B[39m \u001B[43mdsp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemplate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;66;03m# Note: query_only=True means the instructions and examples are not included.\u001B[39;00m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m dsp\u001B[38;5;241m.\u001B[39msettings\u001B[38;5;241m.\u001B[39mcontext(lm\u001B[38;5;241m=\u001B[39mlm, query_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\primitives\\predict.py:73\u001B[0m, in \u001B[0;36m_generate.<locals>.do_generate\u001B[1;34m(example, stage, max_depth, original_example)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;66;03m# Generate and extract the fields.\u001B[39;00m\n\u001B[0;32m     72\u001B[0m prompt \u001B[38;5;241m=\u001B[39m template(example)\n\u001B[1;32m---> 73\u001B[0m completions: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]] \u001B[38;5;241m=\u001B[39m generator(prompt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     74\u001B[0m completions: \u001B[38;5;28mlist\u001B[39m[Example] \u001B[38;5;241m=\u001B[39m [template\u001B[38;5;241m.\u001B[39mextract(example, p) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m completions]\n\u001B[0;32m     76\u001B[0m \u001B[38;5;66;03m# Find the completions that are most complete.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\modules\\gpt3.py:180\u001B[0m, in \u001B[0;36mGPT3.__call__\u001B[1;34m(self, prompt, only_completed, return_sorted, **kwargs)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m return_sorted \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor now\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;66;03m# if kwargs.get(\"n\", 1) > 1:\u001B[39;00m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;66;03m#     if self.model_type == \"chat\":\u001B[39;00m\n\u001B[0;32m    176\u001B[0m \u001B[38;5;66;03m#         kwargs = {**kwargs}\u001B[39;00m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;66;03m#     else:\u001B[39;00m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;66;03m#         kwargs = {**kwargs, \"logprobs\": 5}\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(prompt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_usage(response)\n\u001B[0;32m    183\u001B[0m choices \u001B[38;5;241m=\u001B[39m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\backoff\\_sync.py:105\u001B[0m, in \u001B[0;36mretry_exception.<locals>.retry\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     96\u001B[0m details \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m\"\u001B[39m: target,\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124margs\u001B[39m\u001B[38;5;124m\"\u001B[39m: args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: elapsed,\n\u001B[0;32m    102\u001B[0m }\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 105\u001B[0m     ret \u001B[38;5;241m=\u001B[39m target(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m exception \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    107\u001B[0m     max_tries_exceeded \u001B[38;5;241m=\u001B[39m (tries \u001B[38;5;241m==\u001B[39m max_tries_value)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\modules\\gpt3.py:146\u001B[0m, in \u001B[0;36mGPT3.request\u001B[1;34m(self, prompt, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_type\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 146\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbasic_request(prompt, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\modules\\gpt3.py:119\u001B[0m, in \u001B[0;36mGPT3.basic_request\u001B[1;34m(self, prompt, **kwargs)\u001B[0m\n\u001B[0;32m    117\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m messages\n\u001B[0;32m    118\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstringify_request\u001B[39m\u001B[38;5;124m\"\u001B[39m: json\u001B[38;5;241m.\u001B[39mdumps(kwargs)}\n\u001B[1;32m--> 119\u001B[0m     response \u001B[38;5;241m=\u001B[39m chat_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m prompt\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\modules\\gpt3.py:271\u001B[0m, in \u001B[0;36mchat_request\u001B[1;34m(**kwargs)\u001B[0m\n\u001B[0;32m    268\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m OPENAI_LEGACY:\n\u001B[0;32m    269\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _cached_gpt3_turbo_request_v2_wrapped(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 271\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m v1_cached_gpt3_turbo_request_v2_wrapped(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\u001B[38;5;241m.\u001B[39mmodel_dump()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\modules\\cache_utils.py:16\u001B[0m, in \u001B[0;36mnoop_decorator.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\modules\\gpt3.py:264\u001B[0m, in \u001B[0;36mv1_cached_gpt3_turbo_request_v2_wrapped\u001B[1;34m(**kwargs)\u001B[0m\n\u001B[0;32m    261\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mlru_cache(maxsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m cache_turn_on \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    262\u001B[0m \u001B[38;5;129m@NotebookCacheMemory\u001B[39m\u001B[38;5;241m.\u001B[39mcache\n\u001B[0;32m    263\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mv1_cached_gpt3_turbo_request_v2_wrapped\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 264\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m v1_cached_gpt3_turbo_request_v2(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py:655\u001B[0m, in \u001B[0;36mMemorizedFunc.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    654\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cached_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py:598\u001B[0m, in \u001B[0;36mMemorizedFunc._cached_call\u001B[1;34m(self, args, kwargs, shelving)\u001B[0m\n\u001B[0;32m    595\u001B[0m     must_call \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m must_call:\n\u001B[1;32m--> 598\u001B[0m     out, metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcall(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    599\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmmap_mode \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    600\u001B[0m         \u001B[38;5;66;03m# Memmap the output at the first call to be consistent with\u001B[39;00m\n\u001B[0;32m    601\u001B[0m         \u001B[38;5;66;03m# later calls\u001B[39;00m\n\u001B[0;32m    602\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verbose:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\memory.py:856\u001B[0m, in \u001B[0;36mMemorizedFunc.call\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;28mprint\u001B[39m(format_call(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc, args, kwargs))\n\u001B[1;32m--> 856\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    857\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore_backend\u001B[38;5;241m.\u001B[39mdump_item(\n\u001B[0;32m    858\u001B[0m     [func_id, args_id], output, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_verbose)\n\u001B[0;32m    860\u001B[0m duration \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dsp\\modules\\gpt3.py:258\u001B[0m, in \u001B[0;36mv1_cached_gpt3_turbo_request_v2\u001B[1;34m(**kwargs)\u001B[0m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstringify_request\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[0;32m    257\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstringify_request\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m--> 258\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m openai\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_utils\\_utils.py:277\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    275\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[1;32m--> 277\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\chat\\completions.py:643\u001B[0m, in \u001B[0;36mCompletions.create\u001B[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[0;32m    609\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[0;32m    611\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    641\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[0;32m    642\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m--> 643\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_post\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    644\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/chat/completions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    645\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaybe_transform\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    646\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m    647\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrequency_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrequency_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    650\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunction_call\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_call\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    651\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfunctions\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    652\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogit_bias\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogit_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    653\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlogprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    654\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_tokens\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    655\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    656\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mparallel_tool_calls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel_tool_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    657\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpresence_penalty\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mpresence_penalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    658\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mresponse_format\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    659\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseed\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    660\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mservice_tier\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mservice_tier\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    661\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    662\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    663\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstream_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    664\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtemperature\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    665\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtool_choice\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtool_choice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    666\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtools\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    667\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_logprobs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    668\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtop_p\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    669\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    670\u001B[0m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    671\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcompletion_create_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCompletionCreateParams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    674\u001B[0m \u001B[43m            \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mStream\u001B[49m\u001B[43m[\u001B[49m\u001B[43mChatCompletionChunk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py:1266\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[0;32m   1252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1254\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1261\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1262\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m   1263\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[0;32m   1264\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[0;32m   1265\u001B[0m     )\n\u001B[1;32m-> 1266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py:942\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    933\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[0;32m    934\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    935\u001B[0m     cast_to: Type[ResponseT],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    940\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    941\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m--> 942\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    947\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    948\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py:978\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[0;32m    975\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSending HTTP Request: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, request\u001B[38;5;241m.\u001B[39mmethod, request\u001B[38;5;241m.\u001B[39murl)\n\u001B[0;32m    977\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 978\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39msend(\n\u001B[0;32m    979\u001B[0m         request,\n\u001B[0;32m    980\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_stream_response_body(request\u001B[38;5;241m=\u001B[39mrequest),\n\u001B[0;32m    981\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    982\u001B[0m     )\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    984\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered httpx.TimeoutException\u001B[39m\u001B[38;5;124m\"\u001B[39m, exc_info\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py:914\u001B[0m, in \u001B[0;36mClient.send\u001B[1;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[0;32m    906\u001B[0m follow_redirects \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    907\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfollow_redirects\n\u001B[0;32m    908\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(follow_redirects, UseClientDefault)\n\u001B[0;32m    909\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m follow_redirects\n\u001B[0;32m    910\u001B[0m )\n\u001B[0;32m    912\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[1;32m--> 914\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    921\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py:942\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[1;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[0;32m    939\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[0;32m    941\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 942\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    944\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    945\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    946\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    947\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    948\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py:979\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[1;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    977\u001B[0m     hook(request)\n\u001B[1;32m--> 979\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    981\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_client.py:1015\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m   1010\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1011\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1012\u001B[0m     )\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[1;32m-> 1015\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mtransport\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1017\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[0;32m   1019\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpx\\_transports\\default.py:233\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    220\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[0;32m    221\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[0;32m    222\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    230\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    231\u001B[0m )\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m--> 233\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[0;32m    238\u001B[0m     status_code\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mstatus,\n\u001B[0;32m    239\u001B[0m     headers\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[0;32m    240\u001B[0m     stream\u001B[38;5;241m=\u001B[39mResponseStream(resp\u001B[38;5;241m.\u001B[39mstream),\n\u001B[0;32m    241\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mresp\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[0;32m    242\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    213\u001B[0m         closing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assign_requests_to_connections()\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_connections(closing)\n\u001B[1;32m--> 216\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, Iterable)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    192\u001B[0m connection \u001B[38;5;241m=\u001B[39m pool_request\u001B[38;5;241m.\u001B[39mwait_for_connection(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[1;32m--> 196\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[0;32m    204\u001B[0m     pool_request\u001B[38;5;241m.\u001B[39mclear_connection()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m--> 101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_connection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_closed\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_closed()\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001B[0m, in \u001B[0;36mHTTP11Connection.handle_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreceive_response_headers\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs\n\u001B[0;32m    106\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m    107\u001B[0m     (\n\u001B[0;32m    108\u001B[0m         http_version,\n\u001B[0;32m    109\u001B[0m         status,\n\u001B[0;32m    110\u001B[0m         reason_phrase,\n\u001B[0;32m    111\u001B[0m         headers,\n\u001B[0;32m    112\u001B[0m         trailing_data,\n\u001B[1;32m--> 113\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_receive_response_headers(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    114\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    115\u001B[0m         http_version,\n\u001B[0;32m    116\u001B[0m         status,\n\u001B[0;32m    117\u001B[0m         reason_phrase,\n\u001B[0;32m    118\u001B[0m         headers,\n\u001B[0;32m    119\u001B[0m     )\n\u001B[0;32m    121\u001B[0m network_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_stream\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_response_headers\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    183\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeouts\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 186\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11\u001B[38;5;241m.\u001B[39mResponse):\n\u001B[0;32m    188\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001B[0m, in \u001B[0;36mHTTP11Connection._receive_event\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    221\u001B[0m     event \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mnext_event()\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11\u001B[38;5;241m.\u001B[39mNEED_DATA:\n\u001B[1;32m--> 224\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_network_stream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    234\u001B[0m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h11_state\u001B[38;5;241m.\u001B[39mtheir_state \u001B[38;5;241m==\u001B[39m h11\u001B[38;5;241m.\u001B[39mSEND_RESPONSE:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001B[0m, in \u001B[0;36mSyncStream.read\u001B[1;34m(self, max_bytes, timeout)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n\u001B[1;32m--> 126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1259\u001B[0m, in \u001B[0;36mSSLSocket.recv\u001B[1;34m(self, buflen, flags)\u001B[0m\n\u001B[0;32m   1255\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1256\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1257\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1258\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1259\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuflen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1260\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1261\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv(buflen, flags)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1132\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1133\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m SSLError \u001B[38;5;28;01mas\u001B[39;00m x:\n\u001B[0;32m   1134\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m SSL_ERROR_EOF \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msuppress_ragged_eofs:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 5: Context-Awareness"
   ],
   "id": "c3bfd9e3b5c0bbfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "context_aware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.',\n",
    "                                       rationalization='Large items fit more contents, making them desirable, so they increase the price. People associate red with the devil, so this color decreases the price.')\n",
    "context_aware_result = metrics.context_awareness(test_input, context_aware_output, grader)\n",
    "assert context_aware_result >= max_score/2, context_aware_result\n",
    "\n",
    "context_unaware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.', \n",
    "                                         rationalization='No idea why.')\n",
    "context_unaware_result = metrics.context_awareness(test_input, context_unaware_output, grader)\n",
    "assert context_unaware_result == 0, context_unaware_result"
   ],
   "id": "8375bcc0043ea6ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Compare Datasets\n",
    "\n",
    "In the following code block, we verify our metric functionality by comparing average score on our gold standard dataset (used to tune the metrics) to other datasets that use different styles of explanations. We expect the gold standard average score to be very close to 2*len(metrics) (since each metric is scored on a scale of 0-2), and the other datasets to be lower.\n",
    " \n",
    "TODO: We do not currently verify the context awareness metric, as the gold-standard dataset does not include a rationalization"
   ],
   "id": "ff5cda333b3fc86f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metric_verification_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "labeled_train, labeled_eval, unlabeled_train, unlabeled_eval = examples.get_data(\"gold_standards.json\")\n",
    "train_data = labeled_train + unlabeled_train\n",
    "eval_data = labeled_eval + unlabeled_eval\n",
    "max_optimal_length = max([len(d.narrative) for d in labeled_train])\n",
    "\n",
    "example_good_narratives = random.sample([d.narrative for d in labeled_train], 5)\n",
    "example_bad_narratives = random.sample([d.bad_narrative for d in labeled_train if hasattr(d, \"bad_narrative\")], 5)\n",
    "\n",
    "# Example datasets do not include a rationalization, so we skip context awareness \n",
    "ver_metrics = metrics.Metrics(\n",
    "    [\n",
    "        metrics.accuracy,\n",
    "        metrics.fluency,\n",
    "        metrics.conciseness,\n",
    "        #metrics.completeness\n",
    "    ], verbose=0, openai_key=openai_api_key,\n",
    "    metric_kwargs={\"conciseness\": {\"max_optimal_length\": max_optimal_length},\n",
    "                   \"fluency\": {\"good_narratives\": example_good_narratives, \"bad_narratives\": example_bad_narratives}}\n",
    ")\n",
    "\n",
    "for dataset in metric_verification_datasets: \n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    all_results = None\n",
    "    score = 0\n",
    "    for example in labeled_train:\n",
    "        result = ver_metrics(example, example)\n",
    "        score += result[0]\n",
    "        if all_results is None:\n",
    "            all_results = result[1]\n",
    "        else:\n",
    "            all_results += result[1]\n",
    "    print(f\"Dataset: {dataset}, Average score: {score/len(labeled_train)}/{len(ver_metrics.metric_funcs)*4.0}\")\n",
    "    print(all_results/len(labeled_train))"
   ],
   "id": "7b59478832886fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Failing Cases"
   ],
   "id": "cc5f59cef2f2ca2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inaccurate_output = dspy.Prediction(narrative='The size being 5 decreased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "misleading_output = dspy.Prediction(narrative='Surprisingly, the large house size of 5 increased the predicted price')\n",
    "misleading_result = metrics.accuracy(test_input, misleading_output, grader=grader)\n",
    "assert 0 < misleading_result < 4, misleading_result"
   ],
   "id": "761fe0aa9fc2f680",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "5c9ab560813b91c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
