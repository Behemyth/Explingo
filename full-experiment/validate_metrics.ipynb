{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-26T17:58:29.526873Z",
     "start_time": "2024-08-26T17:58:28.002970Z"
    }
   },
   "source": [
    "import metrics2 as metrics\n",
    "import dspy\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import random\n",
    "import examples\n",
    "\n",
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "    \n",
    "grader = dspy.OpenAI(\n",
    "            model=\"gpt-4o\",\n",
    "            model_type=\"chat\",\n",
    "            max_tokens=2000,\n",
    "            api_key=openai_api_key,\n",
    "            temperature=0.3,\n",
    "        )\n",
    "    \n",
    "max_score = metrics.MAX_SCORE"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:58:29.542876Z",
     "start_time": "2024-08-26T17:58:29.527857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "empty_input = dspy.Example()"
   ],
   "id": "a4319ae8323cd4de",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 1: Conciseness"
   ],
   "id": "403a161d8d30b1cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:58:29.558863Z",
     "start_time": "2024-08-26T17:58:29.544875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "short_output = dspy.Prediction(narrative='word ')\n",
    "short_result = metrics.conciseness(empty_input, short_output, max_optimal_length=10)\n",
    "assert short_result == max_score, short_result\n",
    "\n",
    "long_output = dspy.Prediction(narrative='word ' * 21)\n",
    "long_result = metrics.conciseness(empty_input, long_output, max_optimal_length=10)\n",
    "assert long_result == 0, long_result\n",
    "\n",
    "med_output = dspy.Prediction(narrative='word ' * 15)\n",
    "med_result = metrics.conciseness(empty_input, med_output, max_optimal_length=10)\n",
    "assert med_result == max_score / 2, med_result"
   ],
   "id": "9cb6db83bfc4843e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 2: Accuracy"
   ],
   "id": "79045feb8d8af121"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:58:30.453590Z",
     "start_time": "2024-08-26T17:58:29.560862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "accurate_result = metrics.accuracy(test_input, accurate_output, grader=grader)\n",
    "assert accurate_result == max_score, accurate_result\n",
    "\n",
    "inaccurate_output = dspy.Prediction(narrative='The size being 4 increased the prediction by 11. The color being red decreased the prediction by 9.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "incomplete_but_accurate_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10.')\n",
    "incomplete_but_accurate_result = metrics.accuracy(test_input, incomplete_but_accurate_output, grader=grader)\n",
    "assert incomplete_but_accurate_result == max_score, incomplete_but_accurate_result"
   ],
   "id": "14168fb360045bcc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 3: Completeness"
   ],
   "id": "583c04d26f9b3e7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:59:48.566879Z",
     "start_time": "2024-08-26T17:59:46.968713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8), (Shape, Square, 3)', \n",
    "                          explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "complete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10. The color being red decreased the prediction by 8. The shape being square increased the prediction by 3.')\n",
    "complete_result = metrics.completeness(test_input, complete_output, grader)\n",
    "assert complete_result == max_score, complete_result\n",
    "\n",
    "incomplete_output = dspy.Prediction(narrative='The size being 5 increased the prediction by 10')\n",
    "incomplete_result = metrics.completeness(test_input, incomplete_output, grader)\n",
    "assert incomplete_result == 0, incomplete_result"
   ],
   "id": "23379cf2fdd4aa59",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:59:32.091360Z",
     "start_time": "2024-08-26T17:58:45.167422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "completeness_dataset = json.load(open(\"completeness_tests.json\"))\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "for example in completeness_dataset:\n",
    "    test_input = dspy.Example(explanation=example[\"explanation\"], explanation_format=example[\"explanation_format\"])\n",
    "    test_output = dspy.Prediction(narrative=example[\"narrative\"])\n",
    "    result = metrics.completeness(test_input, test_output, grader)\n",
    "    preds.append(result)\n",
    "    actuals.append(example[\"completeness_score\"])\n",
    "\n",
    "cm = confusion_matrix(actuals, preds, labels=[0.0, 2.0, 4.0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0.0, 2.0, 4.0])\n",
    "disp.plot()"
   ],
   "id": "ccb29b25ae81c281",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2837bc19a80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:59:34.918004Z",
     "start_time": "2024-08-26T17:59:34.903983Z"
    }
   },
   "cell_type": "code",
   "source": "grader.inspect_history(n=1)",
   "id": "e7139317c1519015",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Assess a narrative based on a rubric.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Narrative: ${narrative}\n",
      "\n",
      "Rubric: ${rubric}\n",
      "\n",
      "Start by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Feature-by-feature processing of the narrative.\n",
      "\n",
      "Assessment: A single number from the options in the rubric. Provide only a single number with no other text.\n",
      "\n",
      "---\n",
      "\n",
      "Question: How completely does the narrative below describe the explanation given in <<>>? Explanation format: SHAP feature contribution in (feature_name, feature_value, contribution) format. Explanation: <<(Number of past class failures, 0.00, 0.89), (Wants to take higher education, yes, 0.50), (Amount of free time after school (1-5), 4.00, -0.35), (School, GP, 0.33)>>\n",
      "\n",
      "Narrative: The student's lack of past class failures and desire for higher education significantly increase the predicted grade. However, the student's free time after school (rated 4/5) and school (GP) reputation slightly decrease the predicted grade.\n",
      "\n",
      "Rubric: 0 - One or more feature names from the explanation are not mentioned at all in the narrative. 2 - All features are mentioned, but not all feature values and/or contribution directions. 4 - All features are mentioned, and for each feature, includes at least an approximation of the feature's value and contribution direction.\n",
      "\n",
      "Start by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Assessment: 4\n",
      "\n",
      "Assessment: 4\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nAssess a narrative based on a rubric.\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\n\\nNarrative: ${narrative}\\n\\nRubric: ${rubric}\\n\\nStart by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Feature-by-feature processing of the narrative.\\n\\nAssessment: A single number from the options in the rubric. Provide only a single number with no other text.\\n\\n---\\n\\nQuestion: How completely does the narrative below describe the explanation given in <<>>? Explanation format: SHAP feature contribution in (feature_name, feature_value, contribution) format. Explanation: <<(Number of past class failures, 0.00, 0.89), (Wants to take higher education, yes, 0.50), (Amount of free time after school (1-5), 4.00, -0.35), (School, GP, 0.33)>>\\n\\nNarrative: The student's lack of past class failures and desire for higher education significantly increase the predicted grade. However, the student's free time after school (rated 4/5) and school (GP) reputation slightly decrease the predicted grade.\\n\\nRubric: 0 - One or more feature names from the explanation are not mentioned at all in the narrative. 2 - All features are mentioned, but not all feature values and/or contribution directions. 4 - All features are mentioned, and for each feature, includes at least an approximation of the feature's value and contribution direction.\\n\\nStart by listing out all the features in the explanations, and then determine every feature is present in the narrative, along with its value and contribution direction. Assessment: 4\\n\\nAssessment:\\x1b[32m 4\\x1b[0m\\n\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 4: Fluency\n",
    "\n",
    "We test fluency with two methods:\n",
    "1. A few basic unit tests\n",
    "2. Ensuring that fluency consistently scores higher on whatever dataset is labeled gold standard dataset than on other datasets"
   ],
   "id": "f513c89283bc9ed5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "good_narratives = ['The large size increased the prediction by 100, while the green color decreased it by about 20',\n",
    "                   \"The item's small size of 2 decreased the prediction by about 4, while its blue color increased it by 3\"]\n",
    "\n",
    "fluent_output = dspy.Prediction(narrative='The large size increased the prediction by about 10, while the red color decreased it by 8.')\n",
    "fluent_result = metrics.fluency(empty_input, fluent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "influent_output = dspy.Prediction(narrative='The size (5) increased the prediction (10.5). The color (red) decreased it (8.2)')\n",
    "influent_result = metrics.fluency(empty_input, influent_output, grader, good_narratives=good_narratives)\n",
    "\n",
    "assert influent_result < fluent_result, str(influent_result) + \" \" + str(fluent_result)\n",
    "assert fluent_result == max_score, fluent_result\n",
    "\n",
    "very_influent_output = dspy.Prediction(narrative='Size 5 10.5 color red')\n",
    "very_influent_result = metrics.fluency(empty_input, very_influent_output, grader, good_narratives=good_narratives)\n",
    "assert very_influent_result == 0, very_influent_result"
   ],
   "id": "2214a9f493150063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "validation_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "loaded_datasets = {}\n",
    "for dataset in validation_datasets:\n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    loaded_datasets[dataset] = labeled_train\n",
    "\n",
    "def validate_fluency(gold_standard_dataset):\n",
    "    example_good_narratives = random.sample([d.narrative for d in loaded_datasets[gold_standard_dataset]], 5)\n",
    "    all_results = {}\n",
    "    for dataset in loaded_datasets:\n",
    "        all_results[dataset] = 0\n",
    "        for example in loaded_datasets[dataset]:\n",
    "            all_results[dataset] += metrics.fluency(empty_input, example, grader, good_narratives=example_good_narratives)\n",
    "        all_results[dataset] /= len(loaded_datasets[dataset])\n",
    "    print(f\"Gold standard: {gold_standard_dataset}\")\n",
    "    for dataset in all_results:\n",
    "        if dataset == gold_standard_dataset:\n",
    "            print(f\"**Dataset: {dataset}, Average score: {all_results[dataset]:.2f}\")\n",
    "        else:\n",
    "            print(f\"--Dataset: {dataset}, Average score: {all_results[dataset]:.2f}\")\n",
    "    print()\n",
    "    \n",
    "for dataset in loaded_datasets:\n",
    "    validate_fluency(dataset)"
   ],
   "id": "605caeedebe5ccc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Test 5: Context-Awareness"
   ],
   "id": "c3bfd9e3b5c0bbfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_input = dspy.Example(explanation='(Size, 5, 10), (Color, Red, -8)', explanation_format='(feature_name, feature_value, SHAP contribution)')\n",
    "\n",
    "context_aware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.',\n",
    "                                       rationalization='Large items fit more contents, making them desirable, so they increase the price. People associate red with the devil, so this color decreases the price.')\n",
    "context_aware_result = metrics.context_awareness(test_input, context_aware_output, grader)\n",
    "assert context_aware_result >= max_score/2, context_aware_result\n",
    "\n",
    "context_unaware_output = dspy.Prediction(narrative = 'The large size of 5 increased the price by 10. The red color decreased the price by 8.', \n",
    "                                         rationalization='No idea why.')\n",
    "context_unaware_result = metrics.context_awareness(test_input, context_unaware_output, grader)\n",
    "assert context_unaware_result == 0, context_unaware_result"
   ],
   "id": "8375bcc0043ea6ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Compare Datasets\n",
    "\n",
    "In the following code block, we verify our metric functionality by comparing average score on our gold standard dataset (used to tune the metrics) to other datasets that use different styles of explanations. We expect the gold standard average score to be very close to 2*len(metrics) (since each metric is scored on a scale of 0-2), and the other datasets to be lower.\n",
    " \n",
    "TODO: We do not currently verify the context awareness metric, as the gold-standard dataset does not include a rationalization"
   ],
   "id": "ff5cda333b3fc86f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metric_verification_datasets = [\"gold_standards.json\", \"unaligned_examples_1.json\", \"unaligned_examples_2.json\"]\n",
    "\n",
    "labeled_train, labeled_eval, unlabeled_train, unlabeled_eval = examples.get_data(\"gold_standards.json\")\n",
    "train_data = labeled_train + unlabeled_train\n",
    "eval_data = labeled_eval + unlabeled_eval\n",
    "max_optimal_length = max([len(d.narrative) for d in labeled_train])\n",
    "\n",
    "example_good_narratives = random.sample([d.narrative for d in labeled_train], 5)\n",
    "example_bad_narratives = random.sample([d.bad_narrative for d in labeled_train if hasattr(d, \"bad_narrative\")], 5)\n",
    "\n",
    "# Example datasets do not include a rationalization, so we skip context awareness \n",
    "ver_metrics = metrics.Metrics(\n",
    "    [\n",
    "        metrics.accuracy,\n",
    "        metrics.fluency,\n",
    "        metrics.conciseness,\n",
    "        #metrics.completeness\n",
    "    ], verbose=0, openai_key=openai_api_key,\n",
    "    metric_kwargs={\"conciseness\": {\"max_optimal_length\": max_optimal_length},\n",
    "                   \"fluency\": {\"good_narratives\": example_good_narratives, \"bad_narratives\": example_bad_narratives}}\n",
    ")\n",
    "\n",
    "for dataset in metric_verification_datasets: \n",
    "    labeled_train, _, _, _ = examples.get_data(dataset, split=1)\n",
    "    all_results = None\n",
    "    score = 0\n",
    "    for example in labeled_train:\n",
    "        result = ver_metrics(example, example)\n",
    "        score += result[0]\n",
    "        if all_results is None:\n",
    "            all_results = result[1]\n",
    "        else:\n",
    "            all_results += result[1]\n",
    "    print(f\"Dataset: {dataset}, Average score: {score/len(labeled_train)}/{len(ver_metrics.metric_funcs)*4.0}\")\n",
    "    print(all_results/len(labeled_train))"
   ],
   "id": "7b59478832886fed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Failing Cases"
   ],
   "id": "cc5f59cef2f2ca2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "inaccurate_output = dspy.Prediction(narrative='The size being 5 decreased the prediction by 10. The color being red decreased the prediction by 8.')\n",
    "inaccurate_result = metrics.accuracy(test_input, inaccurate_output, grader=grader)\n",
    "assert inaccurate_result == 0, inaccurate_result\n",
    "\n",
    "misleading_output = dspy.Prediction(narrative='Surprisingly, the large house size of 5 increased the predicted price')\n",
    "misleading_result = metrics.accuracy(test_input, misleading_output, grader=grader)\n",
    "assert 0 < misleading_result < 4, misleading_result"
   ],
   "id": "761fe0aa9fc2f680",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "5c9ab560813b91c6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
