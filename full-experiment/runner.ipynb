{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Explingo Experiment Runner\n",
    "\n",
    "This notebook:\n",
    "1. Loads the gold-standard dataset, prepares the metrics functions, and verifies that the metric functions give the maximum score on the gold-standard dataset, and lower scores on less aligned datasets\n",
    "2. Runs the prompt-design, few-shot, and bootstrap-few-shot experiments on a testing dataset"
   ],
   "id": "a9c2d95909e76143"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Import necessary libraries and prepare the LLM\n",
    "\n",
    "**Note: To run these cells, you need a `keys.yaml` file in the top-level Explingo directory with the following line:**\n",
    "```yaml\n",
    "openai_api_key: <your_openai_api_key>\n",
    "```"
   ],
   "id": "743e31b8c011c24"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-27T18:42:23.762280Z",
     "start_time": "2024-08-27T18:42:21.837554Z"
    }
   },
   "source": [
    "from experiment_runner import ExplingoExperimentRunner\n",
    "import os\n",
    "import yaml\n",
    "import dspy\n",
    "import metrics\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "\n",
    "llm = dspy.OpenAI(model='gpt-4o', api_key=openai_api_key, max_tokens=2000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-27T18:42:23.778278Z",
     "start_time": "2024-08-27T18:42:23.768284Z"
    }
   },
   "id": "6e9d56b95001b3ac",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we create the main experiment runner object. This object takes in a dataset, and then\n",
    "1. Splits the dataset into a training dataset and a testing dataset (see notes below)\n",
    "2. Sets up the evaluation metrics (see notes below). The fluency metric is set up to use sample from the dataset as reference\n",
    "3. Runs the experiments on the testing dataset"
   ],
   "id": "36792a8e050d0f6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Some examples in the testing datasets include gold-standard narratives; others include only a sample explanation.\n",
    "- The former makes up the gold-standard dataset used for tuning the evaluation metrics and providing few-shot examples.\n",
    "- The latter makes up the testing dataset used for evaluation and for bootstrapping few-shot examples"
   ],
   "id": "70871e15ba810c46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We use the following metrics, all scored on a scale from 0-4:\n",
    "- Accuracy: the narrative accurately describes the information in the explanation\n",
    "- Fluency: the narrative is coherent and natural, as compared to the gold-standard explanations. We pass in a small list of sample narratives from the gold-standard dataset to compare against\n",
    "- Conciseness: the narrative is not too long, as compared to the gold-standard explanations. For now, any narrative that is no longer than the longest gold-standard narrative will score 4\n",
    "- Completeness: the narrative includes all relevant information from the original explanation \n",
    "\n",
    "**Note: You can set `verbose=1` to see the narratives generated, or `verbose=2` to see the explanations, narratives, and rationalizations**"
   ],
   "id": "733553c62a1d557d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T18:42:23.793694Z",
     "start_time": "2024-08-27T18:42:23.780278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# iterate all datasets in the eval_data folder\n",
    "runners = {}\n",
    "for dataset in os.listdir(os.path.join(\"eval_data\")):\n",
    "    runners[dataset] = ExplingoExperimentRunner(llm=llm, openai_api_key=openai_api_key, dataset_filepath = os.path.join(\"eval_data\", dataset), verbose=0)"
   ],
   "id": "9ac27ac4e6ca2496",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic prompt design experiment\n",
    "\n",
    "We begin with basic prompts. With 4 metrics (without completeness), each with a score of 0-2, the maximum score is 8. \n",
    "\n",
    "We generate narratives/rationalizations on `max_iters=5` sample explanations, and return the average total score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5694bfd440f310"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T18:42:23.809691Z",
     "start_time": "2024-08-27T18:42:23.795692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utility for cleaner results\n",
    "\n",
    "def pretty_print(result):\n",
    "    s = f\"Total score: {result[0]}\"\n",
    "    s2 = \", \".join([f\"{k}: {v}\" for k, v in result[1].items()])\n",
    "    print(f\"{s} ({s2})\")"
   ],
   "id": "7b3f0abc65532f7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "prompts = [\n",
    "    \"You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\",\n",
    "    \"You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\",\n",
    "    \"You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\",\n",
    "]\n",
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for prompt in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        pretty_print(runner.run_basic_prompting_experiment(prompt=prompt, max_iters=5))\n",
    "        print(\"--\")\n",
    "    print(\"=====\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-27T18:47:37.414156Z",
     "start_time": "2024-08-27T18:42:23.812691Z"
    }
   },
   "id": "1be61df6a728fa29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gold_standards.json\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Prompt: You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 3.6, fluency: 3.6, conciseness: 4.0)\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Dataset: unaligned_examples_1.json\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "Prompt: You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\n",
      "Total score: 14.8 (accuracy: 4.0, completeness: 4.0, fluency: 2.8, conciseness: 4.0)\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "Dataset: unaligned_examples_2.json\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "Prompt: You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Few-shot experiment\n",
    "\n",
    "Next, we repeat the experiment with the addition of N few-shot examples from the gold-standard dataset."
   ],
   "id": "89d7ba7e0085534b"
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i in [1, 3, 5]:\n",
    "        print(f\"Few-shot n: {i}\")\n",
    "        pretty_print(runner.run_few_shot_experiment( max_iters=5, n_few_shot=i))\n",
    "        print(\"--\")\n",
    "    print(\"=====\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-27T18:54:20.290879Z",
     "start_time": "2024-08-27T18:47:37.415968Z"
    }
   },
   "id": "c57212f361799ac6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gold_standards.json\n",
      "Few-shot n: 1\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Few-shot n: 3\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Few-shot n: 5\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Dataset: unaligned_examples_1.json\n",
      "Few-shot n: 1\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Few-shot n: 3\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Few-shot n: 5\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Dataset: unaligned_examples_2.json\n",
      "Few-shot n: 1\n",
      "Total score: 15.4 (accuracy: 4.0, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "Few-shot n: 3\n",
      "Total score: 15.4 (accuracy: 4.0, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "Few-shot n: 5\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 3.6, fluency: 3.6, conciseness: 4.0)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bootstrapped few-shot\n",
    "Next, we repeat the experiment with the addition of 3 examples bootstrapped by DSPy to optimize the evaluation metrics."
   ],
   "id": "6e0ff9cf578f5b7b"
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i, j in [[0, 3], [0, 5], [3, 3], [3, 5]]:\n",
    "        print(f\"Few-shot n: {i}, Bootstrapped n: {j}\")\n",
    "        pretty_print(runner.run_bootstrap_few_shot_experiment(max_iters=5, n_labeled_few_shot=i, n_bootstrapped_few_shot=j))\n",
    "        print(\"--\")\n",
    "    print(\"=====\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-27T18:58:00.342804Z",
     "start_time": "2024-08-27T18:54:20.292783Z"
    }
   },
   "id": "7bb946a284aff621",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gold_standards.json\n",
      "Few-shot n: 0, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:01<00:09,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 157.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 165.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 130.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 150.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Few-shot n: 0, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:01<00:04,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 143.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 102.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 104.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 154.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Few-shot n: 3, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 156.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 142.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 149.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 157.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 3/21 [00:00<00:00, 150.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Few-shot n: 3, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 138.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 136.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 135.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 138.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 5/21 [00:00<00:00, 121.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n",
      "Total score: 16.0 (accuracy: 4.0, completeness: 4.0, fluency: 4.0, conciseness: 4.0)\n",
      "Dataset: unaligned_examples_1.json\n",
      "Few-shot n: 0, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:01<00:02,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 125.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 157.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 130.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 166.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n",
      "Total score: 15.4 (accuracy: 4.0, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "Few-shot n: 0, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:01<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 145.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 151.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 166.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 146.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 4.0, fluency: 3.2, conciseness: 4.0)\n",
      "Few-shot n: 3, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 102.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 123.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 142.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 136.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:00<00:00, 130.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples in round 0.\n",
      "Total score: 15.4 (accuracy: 4.0, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "Few-shot n: 3, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 121.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 102.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 110.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 147.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:00<00:00, 136.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 5 full traces after 6 examples in round 0.\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 4.0, fluency: 3.2, conciseness: 4.0)\n",
      "Dataset: unaligned_examples_2.json\n",
      "Few-shot n: 0, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:19<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 124.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 153.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 144.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 169.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "Few-shot n: 0, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 137.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 139.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 139.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 139.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 160.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "Few-shot n: 3, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 136.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 158.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 131.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 157.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 152.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "Few-shot n: 3, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 150.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 162.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 150.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 151.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 143.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T18:58:00.358057Z",
     "start_time": "2024-08-27T18:58:00.344777Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8c9376972f39a1bf",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
