{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Explingo Experiment Runner\n",
    "\n",
    "This notebook:\n",
    "1. Loads the gold-standard dataset, prepares the metrics functions, and verifies that the metric functions give the maximum score on the gold-standard dataset, and lower scores on less aligned datasets\n",
    "2. Runs the prompt-design, few-shot, and bootstrap-few-shot experiments on a testing dataset"
   ],
   "id": "a9c2d95909e76143"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Import necessary libraries and prepare the LLM\n",
    "\n",
    "**Note: To run these cells, you need a `keys.yaml` file in the top-level Explingo directory with the following line:**\n",
    "```yaml\n",
    "openai_api_key: <your_openai_api_key>\n",
    "```"
   ],
   "id": "743e31b8c011c24"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T21:11:30.118803Z",
     "start_time": "2024-09-06T21:11:29.187170Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from experiment_runner import ExplingoExperimentRunner\n",
    "import os\n",
    "import yaml\n",
    "import dspy\n",
    "import metrics\n",
    "import random\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "\n",
    "llm = dspy.OpenAI(model='gpt-4o', api_key=openai_api_key, max_tokens=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T21:11:30.134797Z",
     "start_time": "2024-09-06T21:11:30.119786Z"
    }
   },
   "id": "6e9d56b95001b3ac",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we create the main experiment runner object. This object takes in a dataset, and then\n",
    "1. Splits the dataset into a training dataset and a testing dataset (see notes below)\n",
    "2. Sets up the evaluation metrics (see notes below). The fluency metric is set up to use sample from the dataset as reference\n",
    "3. Runs the experiments on the testing dataset"
   ],
   "id": "36792a8e050d0f6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Some examples in the testing datasets include gold-standard narratives; others include only a sample explanation.\n",
    "- The former makes up the gold-standard dataset used for tuning the evaluation metrics and providing few-shot examples.\n",
    "- The latter makes up the testing dataset used for evaluation and for bootstrapping few-shot examples"
   ],
   "id": "70871e15ba810c46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We use the following metrics, all scored on a scale from 0-4:\n",
    "- Accuracy: the narrative accurately describes the information in the explanation\n",
    "- Fluency: the narrative is coherent and natural, as compared to the gold-standard explanations. We pass in a small list of sample narratives from the gold-standard dataset to compare against\n",
    "- Conciseness: the narrative is not too long, as compared to the gold-standard explanations. For now, any narrative that is no longer than the longest gold-standard narrative will score 4\n",
    "- Completeness: the narrative includes all relevant information from the original explanation \n",
    "\n",
    "**Note: You can set `verbose=1` to see the narratives generated, or `verbose=2` to see the explanations, narratives, and rationalizations**"
   ],
   "id": "733553c62a1d557d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:11:30.242625Z",
     "start_time": "2024-09-06T21:11:30.135776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# iterate all datasets in the eval_data folder\n",
    "runners = {}\n",
    "total_eval = 0\n",
    "for dataset in os.listdir(os.path.join(\"eval_data\")):\n",
    "    runners[dataset] = ExplingoExperimentRunner(llm=llm, openai_api_key=openai_api_key, dataset_filepath = os.path.join(\"eval_data\", dataset), verbose=1)\n",
    "    total_eval += len(runners[dataset].eval_data)\n",
    "    \n",
    "print(\"Total eval examples:\", total_eval)\n",
    "results = []"
   ],
   "id": "9ac27ac4e6ca2496",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_data\\housing_1.json\n",
      "Total number of examples: 35\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 15\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 10\n",
      "Max optimal length: 12.24\n",
      "---\n",
      "eval_data\\housing_2.json\n",
      "Total number of examples: 22\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 7\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 5\n",
      "Max optimal length: 9.0\n",
      "---\n",
      "eval_data\\housing_3.json\n",
      "Total number of examples: 22\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 8\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 4\n",
      "Max optimal length: 6.84\n",
      "---\n",
      "eval_data\\mushroom_1.json\n",
      "Total number of examples: 30\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 6\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 14\n",
      "Max optimal length: 9.9\n",
      "---\n",
      "eval_data\\mushroom_2.json\n",
      "Total number of examples: 30\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 6\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 14\n",
      "Max optimal length: 8.4\n",
      "---\n",
      "eval_data\\pdf_1.json\n",
      "Total number of examples: 30\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 4\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 16\n",
      "Max optimal length: 8.4\n",
      "---\n",
      "eval_data\\pdf_2.json\n",
      "Total number of examples: 30\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 4\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 16\n",
      "Max optimal length: 6.6\n",
      "---\n",
      "eval_data\\student_1.json\n",
      "Total number of examples: 30\n",
      "Labeled training examples: 10\n",
      "Labeled evaluation examples: 20\n",
      "Unlabeled training examples: 0\n",
      "Unlabeled evaluation examples: 0\n",
      "Max optimal length: 12.9\n",
      "---\n",
      "eval_data\\student_2.json\n",
      "Total number of examples: 30\n",
      "Labeled training examples: 5\n",
      "Labeled evaluation examples: 9\n",
      "Unlabeled training examples: 5\n",
      "Unlabeled evaluation examples: 11\n",
      "Max optimal length: 9.6\n",
      "---\n",
      "Total eval examples: 169\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:11:30.258118Z",
     "start_time": "2024-09-06T21:11:30.244608Z"
    }
   },
   "cell_type": "code",
   "source": "checkpoint = 0",
   "id": "37e42840e8a0d1d0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic prompt design experiment\n",
    "\n",
    "We begin with basic prompts. With 4 metrics (without completeness), each with a score of 0-2, the maximum score is 8. \n",
    "\n",
    "We generate narratives/rationalizations on `max_iters=5` sample explanations, and return the average total score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5694bfd440f310"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:11:30.273095Z",
     "start_time": "2024-09-06T21:11:30.259117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utilities for cleaner results\n",
    "\n",
    "def pretty_print(result):\n",
    "    s = f\"Total score: {result[0]}\"\n",
    "    s2 = \", \".join([f\"{k}: {v}\" for k, v in result[1].items()])\n",
    "    print(f\"{s} ({s2})\")\n",
    "    \n",
    "def update_results(method, dataset, scores, kwargs):\n",
    "    result = {\"dataset\": dataset, \"total score\": scores[0]}\n",
    "    result.update(scores[1])\n",
    "    result.update(kwargs)\n",
    "    results.append(result)"
   ],
   "id": "7b3f0abc65532f7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "prompts = [\"You are helping users understand an ML model's prediction. Given an explanation and information about the model, \"\n",
    "           \"convert the explanation into a human-readable narrative.\",\n",
    "           \"You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\",\n",
    "           \"You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\",\n",
    "]\n",
    "\n",
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for prompt in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        scores = runner.run_basic_prompting_experiment(prompt=prompt, max_iters=5)\n",
    "        update_results(\"basic_prompting\", dataset, scores, {\"prompt\": prompt})\n",
    "        pretty_print(scores)\n",
    "        print(\"--\")\n",
    "    with open(f'results_checkpoint.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print(\"=====\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-06T21:11:35.689008Z",
     "start_time": "2024-09-06T21:11:30.274101Z"
    }
   },
   "id": "1be61df6a728fa29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: housing_1.json\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\n",
      "Explanation: (Physical locations within Ames city limits, NoRidge, 23069.89), (Above ground living area square feet, 2198.00, 20125.75), (Second floor square feet, 1053.00, 18094.05), (Rates the overall material and finish of the house, 8.00, 9655.79), (Original construction date, 2000.00, 8192.46)\n",
      "Narrative: The model predicts the house price based on several key factors. The house is located within the Ames city limits, specifically in the NoRidge neighborhood, which contributes significantly to the price with a value of 23069.89. The above ground living area is 2198 square feet, adding 20125.75 to the price. The second floor has 1053 square feet, contributing 18094.05. The overall material and finish of the house are rated at 8, which adds 9655.79 to the price. Lastly, the house was originally constructed in the year 2000, contributing 8192.46 to the final predicted price.\n",
      "Total Score: 12.856209150326798\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 1.856209150326798, \n",
      "--\n",
      "Explanation: (Type of foundation, Wood, -18650.67), (Physical locations within Ames city limits, Mitchel, -13510.92), (Rates the overall material and finish of the house, 5.00, -10743.76), (Three season porch area in square feet, 320.00, 9959.33), (Bedrooms above ground, 1.00, 8905.73)\n",
      "Narrative: The model predicts the house price based on several factors. The type of foundation being wood decreases the price by $18,650.67. The house's location within the Mitchel area of Ames city reduces the price by $13,510.92. The overall material and finish rating of 5.00 lowers the price by $10,743.76. However, having a three-season porch area of 320 square feet increases the price by $9,959.33. Additionally, having one bedroom above ground adds $8,905.73 to the price.\n",
      "Total Score: 14.098039215686274\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 3.098039215686275, \n",
      "--\n",
      "Explanation: (Type 1 finished square feet, 1369.00, 14641.53), (Evaluates the height of the basement, Ex, 13233.24), (Total square feet of basement area, 1686.00, 12138.28), (Second floor square feet, 0.00, -10142.29), (Rates the overall material and finish of the house, 8.00, 9655.79)\n",
      "Narrative: The model predicts the house price based on several key features. The finished square feet of the house, which is 1369 square feet, contributes significantly to the price, adding approximately $14,641.53. The height of the basement, rated as 'Ex', also adds a substantial amount, around $13,233.24. The total square feet of the basement area, which is 1686 square feet, contributes an additional $12,138.28. However, the absence of a second floor (0 square feet) decreases the price by about $10,142.29. Lastly, the overall material and finish of the house, rated at 8, positively impacts the price, adding approximately $9,655.79.\n",
      "Total Score: 12.594771241830067\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 1.594771241830066, \n",
      "--\n",
      "Explanation: (Above ground living area square feet, 2090.00, 16382.07), (Second floor square feet, 983.00, 16216.99), (Physical locations within Ames city limits, NWAmes, -9769.73), (Type 1 finished square feet, 859.00, 6193.63), (Masonry veneer type, Stone, 5446.26)\n",
      "Narrative: The model predicts the house price based on several key features. The above ground living area, which is 2090 square feet, contributes significantly to increasing the price by 16382.07 units. The second floor area, measuring 983 square feet, also adds a substantial 16216.99 units to the price. However, the house's location within the NWAmes area of Ames city reduces the price by 9769.73 units. Additionally, the type 1 finished square feet, which is 859 square feet, increases the price by 6193.63 units. Lastly, having a masonry veneer type of stone adds 5446.26 units to the house price.\n",
      "Total Score: 11.66013071895425\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 2.0, conciseness: 1.6601307189542487, \n",
      "--\n",
      "Explanation: (Exterior covering on house, BrkFace, 16798.14), (Original construction date, 1931.00, -13042.68), (Kitchens above grade, 2.00, -12983.78), (Home functionality, Min1, -11474.19), (Second floor square feet, 752.00, 10022.69)\n",
      "Narrative: The model predicts the house price based on several factors. The presence of a brick face exterior adds approximately $16,798.14 to the house price. However, the original construction date being 1931 reduces the price by about $13,042.68. Having two kitchens above grade further decreases the price by around $12,983.78. The home's functionality being rated as 'Min1' lowers the price by approximately $11,474.19. On the positive side, having 752 square feet on the second floor increases the price by about $10,022.69.\n",
      "Total Score: 13.77124183006536\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 2.7712418300653594, \n",
      "--\n",
      "Total score: 12.996078431372549 (accuracy: 4.0, completeness: 4.0, fluency: 2.8, conciseness: 2.1960784313725497)\n",
      "--\n",
      "Prompt: You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\n",
      "Explanation: (Physical locations within Ames city limits, NoRidge, 23069.89), (Above ground living area square feet, 2198.00, 20125.75), (Second floor square feet, 1053.00, 18094.05), (Rates the overall material and finish of the house, 8.00, 9655.79), (Original construction date, 2000.00, 8192.46)\n",
      "Narrative: The model predicts the house price based on several key factors. The house is located within the Ames city limits, specifically in the NoRidge area, which contributes significantly to the price. The above-ground living area is 2,198 square feet, adding a substantial amount to the predicted price. Additionally, the second floor has 1,053 square feet, which also positively impacts the price. The overall material and finish of the house are rated at 8 out of 10, indicating high quality, which further increases the price. Lastly, the house was originally constructed in the year 2000, and this relatively recent construction date contributes to the higher predicted price.\n",
      "Total Score: 12.071895424836601\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 1.071895424836602, \n",
      "--\n",
      "Explanation: (Type of foundation, Wood, -18650.67), (Physical locations within Ames city limits, Mitchel, -13510.92), (Rates the overall material and finish of the house, 5.00, -10743.76), (Three season porch area in square feet, 320.00, 9959.33), (Bedrooms above ground, 1.00, 8905.73)\n",
      "Narrative: The model predicts the house price based on several factors. The type of foundation used for the house decreases the price by $18,650.67. Being located within the Mitchel area of Ames city reduces the price by $13,510.92. The overall material and finish quality of the house, rated as 5, lowers the price by $10,743.76. However, having a three-season porch area of 320 square feet increases the price by $9,959.33. Additionally, having one bedroom above ground adds $8,905.73 to the house price.\n",
      "Total Score: 13.705882352941178\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 2.7058823529411766, \n",
      "--\n",
      "Explanation: (Type 1 finished square feet, 1369.00, 14641.53), (Evaluates the height of the basement, Ex, 13233.24), (Total square feet of basement area, 1686.00, 12138.28), (Second floor square feet, 0.00, -10142.29), (Rates the overall material and finish of the house, 8.00, 9655.79)\n",
      "Narrative: The model predicts the house price based on several factors. The finished square feet of the house contributes significantly to the price, adding $14,641.53 for 1,369 square feet. The height of the basement also plays a crucial role, contributing $13,233.24. The total square feet of the basement area adds $12,138.28 for 1,686 square feet. However, having no second floor reduces the price by $10,142.29. Lastly, the overall material and finish quality of the house, rated at 8, adds $9,655.79 to the price.\n",
      "Total Score: 13.640522875816995\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 2.640522875816994, \n",
      "--\n",
      "Explanation: (Above ground living area square feet, 2090.00, 16382.07), (Second floor square feet, 983.00, 16216.99), (Physical locations within Ames city limits, NWAmes, -9769.73), (Type 1 finished square feet, 859.00, 6193.63), (Masonry veneer type, Stone, 5446.26)\n",
      "Narrative: The model predicts the house price based on several key factors. The size of the above-ground living area, which is 2090 square feet, significantly increases the price by $16,382.07. The second floor, with 983 square feet, also adds $16,216.99 to the price. Being located within the NWAmes area of Ames city reduces the price by $9,769.73. Additionally, having 859 square feet of finished space on the first floor contributes $6,193.63 to the price. Lastly, the presence of a stone masonry veneer adds $5,446.26 to the house price.\n",
      "Total Score: 13.313725490196079\n",
      "accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 2.313725490196079, \n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Few-shot experiment\n",
    "\n",
    "Next, we repeat the experiment with the addition of N few-shot examples from the gold-standard dataset."
   ],
   "id": "89d7ba7e0085534b"
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i in [1, 3, 5]:\n",
    "        print(f\"Few-shot n: {i}\")\n",
    "        scores = runner.run_few_shot_experiment(n_few_shot=i, prompt=prompts[0], max_iters=5)\n",
    "        update_results(\"few_shot\", dataset, scores, {\"n_few_shot\": i, \"prompt\": prompts[0]})\n",
    "        pretty_print(scores)\n",
    "        print(\"--\")\n",
    "    with open(f'results_checkpoint.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print(\"=====\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c57212f361799ac6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bootstrapped few-shot\n",
    "Next, we repeat the experiment with the addition of 3 examples bootstrapped by DSPy to optimize the evaluation metrics."
   ],
   "id": "6e0ff9cf578f5b7b"
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i, j in [[1, 1], [1, 3], [3, 1], [3, 3]]:\n",
    "        print(f\"Few-shot n: {i}, Bootstrapped n: {j}\")\n",
    "        scores = runner.run_bootstrap_few_shot_experiment(n_labeled_few_shot=i, n_bootstrapped_few_shot=j, max_iters=5)\n",
    "        update_results(\"bootstrap_few_shot\", dataset, scores, {\"n_few_shot\": i, \"n_bootstrapped_few_shot\": j, \"prompt\": prompts[0]})\n",
    "        pretty_print(scores)\n",
    "        print(\"--\")\n",
    "    with open(f'results_checkpoint.json', 'w') as f:\n",
    "        json.dump(results, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bb946a284aff621",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# result_df = pd.DataFrame(results)\n",
    "# result_df.to_csv(\"results.csv\")\n",
    "# result_df"
   ],
   "id": "8c9376972f39a1bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "b3ed31a97e1a6e19",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
