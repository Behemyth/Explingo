{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Explingo Experiment Runner\n",
    "\n",
    "This notebook:\n",
    "1. Loads the gold-standard dataset, prepares the metrics functions, and verifies that the metric functions give the maximum score on the gold-standard dataset, and lower scores on less aligned datasets\n",
    "2. Runs the prompt-design, few-shot, and bootstrap-few-shot experiments on a testing dataset"
   ],
   "id": "a9c2d95909e76143"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "Import necessary libraries and prepare the LLM\n",
    "\n",
    "**Note: To run these cells, you need a `keys.yaml` file in the top-level Explingo directory with the following line:**\n",
    "```yaml\n",
    "openai_api_key: <your_openai_api_key>\n",
    "```"
   ],
   "id": "743e31b8c011c24"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-28T15:13:44.194224Z",
     "start_time": "2024-08-28T15:13:44.190766Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from experiment_runner import ExplingoExperimentRunner\n",
    "import os\n",
    "import yaml\n",
    "import dspy\n",
    "import metrics\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "\n",
    "llm = dspy.OpenAI(model='gpt-4o', api_key=openai_api_key, max_tokens=2000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T15:13:44.199811Z",
     "start_time": "2024-08-28T15:13:44.195230Z"
    }
   },
   "id": "6e9d56b95001b3ac",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, we create the main experiment runner object. This object takes in a dataset, and then\n",
    "1. Splits the dataset into a training dataset and a testing dataset (see notes below)\n",
    "2. Sets up the evaluation metrics (see notes below). The fluency metric is set up to use sample from the dataset as reference\n",
    "3. Runs the experiments on the testing dataset"
   ],
   "id": "36792a8e050d0f6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Some examples in the testing datasets include gold-standard narratives; others include only a sample explanation.\n",
    "- The former makes up the gold-standard dataset used for tuning the evaluation metrics and providing few-shot examples.\n",
    "- The latter makes up the testing dataset used for evaluation and for bootstrapping few-shot examples"
   ],
   "id": "70871e15ba810c46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We use the following metrics, all scored on a scale from 0-4:\n",
    "- Accuracy: the narrative accurately describes the information in the explanation\n",
    "- Fluency: the narrative is coherent and natural, as compared to the gold-standard explanations. We pass in a small list of sample narratives from the gold-standard dataset to compare against\n",
    "- Conciseness: the narrative is not too long, as compared to the gold-standard explanations. For now, any narrative that is no longer than the longest gold-standard narrative will score 4\n",
    "- Completeness: the narrative includes all relevant information from the original explanation \n",
    "\n",
    "**Note: You can set `verbose=1` to see the narratives generated, or `verbose=2` to see the explanations, narratives, and rationalizations**"
   ],
   "id": "733553c62a1d557d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:13:44.206594Z",
     "start_time": "2024-08-28T15:13:44.199811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# iterate all datasets in the eval_data folder\n",
    "runners = {}\n",
    "for dataset in os.listdir(os.path.join(\"eval_data\")):\n",
    "    runners[dataset] = ExplingoExperimentRunner(llm=llm, openai_api_key=openai_api_key, dataset_filepath = os.path.join(\"eval_data\", dataset), verbose=0)\n",
    "    \n",
    "results = []"
   ],
   "id": "9ac27ac4e6ca2496",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic prompt design experiment\n",
    "\n",
    "We begin with basic prompts. With 4 metrics (without completeness), each with a score of 0-2, the maximum score is 8. \n",
    "\n",
    "We generate narratives/rationalizations on `max_iters=5` sample explanations, and return the average total score."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5694bfd440f310"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:13:44.210667Z",
     "start_time": "2024-08-28T15:13:44.207600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Utilities for cleaner results\n",
    "\n",
    "def pretty_print(result):\n",
    "    s = f\"Total score: {result[0]}\"\n",
    "    s2 = \", \".join([f\"{k}: {v}\" for k, v in result[1].items()])\n",
    "    print(f\"{s} ({s2})\")\n",
    "    \n",
    "def update_results(method, dataset, scores, kwargs):\n",
    "    result = {\"dataset\": dataset, \"prompt\": prompt, \"total score\": scores[0]}\n",
    "    result.update(scores[1])\n",
    "    result.update(kwargs)\n",
    "    results.append(result)"
   ],
   "id": "7b3f0abc65532f7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "prompts = [\"You are helping users understand an ML model's prediction. Given an explanation and information about the model, \"\n",
    "           \"convert the explanation into a human-readable narrative.\",\n",
    "           \"You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\",\n",
    "           \"You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\",\n",
    "]\n",
    "\n",
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for prompt in prompts:\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        scores = runner.run_basic_prompting_experiment(prompt=prompt, max_iters=5)\n",
    "        update_results(\"basic_prompting\", dataset, scores, {\"prompt\": prompt})\n",
    "        pretty_print(scores)\n",
    "        print(\"--\")\n",
    "    print(\"=====\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T15:19:55.572098Z",
     "start_time": "2024-08-28T15:13:44.210667Z"
    }
   },
   "id": "1be61df6a728fa29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mushroom_1.json\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\n",
      "Total score: 14.2 (accuracy: 4.0, completeness: 4.0, fluency: 2.2, conciseness: 4.0)\n",
      "--\n",
      "Prompt: You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\n",
      "Total score: 13.8 (accuracy: 4.0, completeness: 3.6, fluency: 2.2, conciseness: 4.0)\n",
      "--\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\n",
      "Total score: 14.6 (accuracy: 4.0, completeness: 4.0, fluency: 2.6, conciseness: 4.0)\n",
      "--\n",
      "=====\n",
      "Dataset: pdf_1.json\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\n",
      "Total score: 15.0 (accuracy: 3.2, completeness: 4.0, fluency: 3.8, conciseness: 4.0)\n",
      "--\n",
      "Prompt: You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\n",
      "Total score: 13.8 (accuracy: 3.2, completeness: 3.2, fluency: 3.4, conciseness: 4.0)\n",
      "--\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\n",
      "Total score: 14.4 (accuracy: 3.2, completeness: 4.0, fluency: 3.2, conciseness: 4.0)\n",
      "--\n",
      "=====\n",
      "Dataset: student_1.json\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Prompt: You are helping users who do not have experience working with ML understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Make your answers sound as natural as possible.\n",
      "Total score: 14.6 (accuracy: 4.0, completeness: 3.6, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Prompt: You are helping users understand an ML model's prediction. Given an explanation and information about the model, convert the explanation into a human-readable narrative. Be sure to explicitly mention all values from the explanation in your response.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "=====\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Few-shot experiment\n",
    "\n",
    "Next, we repeat the experiment with the addition of N few-shot examples from the gold-standard dataset."
   ],
   "id": "89d7ba7e0085534b"
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i in [1, 3, 5]:\n",
    "        print(f\"Few-shot n: {i}\")\n",
    "        scores = runner.run_few_shot_experiment(max_iters=5, n_few_shot=i, prompt=prompts[0])\n",
    "        update_results(\"few_shot\", dataset, scores, {\"n_few_shot\": i, \"prompt\": prompts[0]})\n",
    "        pretty_print(scores)\n",
    "        print(\"--\")\n",
    "    print(\"=====\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T15:24:45.233608Z",
     "start_time": "2024-08-28T15:19:55.572098Z"
    }
   },
   "id": "c57212f361799ac6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mushroom_1.json\n",
      "Few-shot n: 1\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 5\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "=====\n",
      "Dataset: pdf_1.json\n",
      "Few-shot n: 1\n",
      "Total score: 14.6 (accuracy: 3.2, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3\n",
      "Total score: 14.8 (accuracy: 3.2, completeness: 4.0, fluency: 3.6, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 5\n",
      "Total score: 15.0 (accuracy: 3.2, completeness: 4.0, fluency: 3.8, conciseness: 4.0)\n",
      "--\n",
      "=====\n",
      "Dataset: student_1.json\n",
      "Few-shot n: 1\n",
      "Total score: 14.8 (accuracy: 4.0, completeness: 3.6, fluency: 3.2, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3\n",
      "Total score: 13.8 (accuracy: 4.0, completeness: 2.8, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 5\n",
      "Total score: 14.8 (accuracy: 4.0, completeness: 3.6, fluency: 3.2, conciseness: 4.0)\n",
      "--\n",
      "=====\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bootstrapped few-shot\n",
    "Next, we repeat the experiment with the addition of 3 examples bootstrapped by DSPy to optimize the evaluation metrics."
   ],
   "id": "6e0ff9cf578f5b7b"
  },
  {
   "cell_type": "code",
   "source": [
    "for dataset in runners:\n",
    "    runner = runners[dataset]\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    for i, j in [[0, 3], [0, 5], [3, 3], [3, 5]]:\n",
    "        print(f\"Few-shot n: {i}, Bootstrapped n: {j}\")\n",
    "        scores = runner.run_bootstrap_few_shot_experiment(max_iters=5, n_labeled_few_shot=i, n_bootstrapped_few_shot=j)\n",
    "        update_results(\"bootstrap_few_shot\", dataset, scores, {\"n_few_shot\": i, \"n_bootstrapped_few_shot\": j, \"prompt\": prompts[0]})\n",
    "        pretty_print(scores)\n",
    "        print(\"--\")\n",
    "    print(\"=====\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T15:35:11.664337Z",
     "start_time": "2024-08-28T15:24:45.233608Z"
    }
   },
   "id": "7bb946a284aff621",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mushroom_1.json\n",
      "Few-shot n: 0, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:56<00:00,  6.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 216.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 219.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 209.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 213.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 0, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 217.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 213.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 217.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 213.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 214.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 211.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 83.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 213.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 211.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 211.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 206.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 215.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 212.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 216.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 214.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 17 examples in round 0.\n",
      "Total score: 15.0 (accuracy: 4.0, completeness: 4.0, fluency: 3.0, conciseness: 4.0)\n",
      "--\n",
      "=====\n",
      "Dataset: pdf_1.json\n",
      "Few-shot n: 0, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:56<01:20,  8.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 205.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 202.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 202.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 205.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n",
      "Total score: 14.6 (accuracy: 3.2, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 0, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:28<00:00,  5.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 213.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 211.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 212.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 216.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n",
      "Total score: 15.4 (accuracy: 4.0, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 205.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 215.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 205.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 215.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [00:00<00:00, 205.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n",
      "Total score: 14.6 (accuracy: 3.2, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 208.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 213.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 215.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 211.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 211.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n",
      "Total score: 15.4 (accuracy: 4.0, completeness: 4.0, fluency: 3.4, conciseness: 4.0)\n",
      "--\n",
      "=====\n",
      "Dataset: student_1.json\n",
      "Few-shot n: 0, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [01:50<00:55,  9.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 210.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 218.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 210.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 214.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 4.0, fluency: 3.2, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 0, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:47<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 211.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 211.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 216.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 212.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 4.0, fluency: 3.2, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3, Bootstrapped n: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 214.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 216.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 210.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 214.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [00:00<00:00, 55.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 4.0, fluency: 3.2, conciseness: 4.0)\n",
      "--\n",
      "Few-shot n: 3, Bootstrapped n: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 208.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 209.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 205.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 192.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 208.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n",
      "Total score: 15.2 (accuracy: 4.0, completeness: 4.0, fluency: 3.2, conciseness: 4.0)\n",
      "--\n",
      "=====\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T15:35:11.685031Z",
     "start_time": "2024-08-28T15:35:11.665343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(\"results.csv\")\n",
    "result_df"
   ],
   "id": "8c9376972f39a1bf",
   "outputs": [
    {
     "data": {
      "text/plain": "            dataset                                             prompt  \\\n0   mushroom_1.json  You are helping users understand an ML model's...   \n1   mushroom_1.json  You are helping users who do not have experien...   \n2   mushroom_1.json  You are helping users understand an ML model's...   \n3        pdf_1.json  You are helping users understand an ML model's...   \n4        pdf_1.json  You are helping users who do not have experien...   \n5        pdf_1.json  You are helping users understand an ML model's...   \n6    student_1.json  You are helping users understand an ML model's...   \n7    student_1.json  You are helping users who do not have experien...   \n8    student_1.json  You are helping users understand an ML model's...   \n9   mushroom_1.json  You are helping users understand an ML model's...   \n10  mushroom_1.json  You are helping users understand an ML model's...   \n11  mushroom_1.json  You are helping users understand an ML model's...   \n12       pdf_1.json  You are helping users understand an ML model's...   \n13       pdf_1.json  You are helping users understand an ML model's...   \n14       pdf_1.json  You are helping users understand an ML model's...   \n15   student_1.json  You are helping users understand an ML model's...   \n16   student_1.json  You are helping users understand an ML model's...   \n17   student_1.json  You are helping users understand an ML model's...   \n18  mushroom_1.json  You are helping users understand an ML model's...   \n19  mushroom_1.json  You are helping users understand an ML model's...   \n20  mushroom_1.json  You are helping users understand an ML model's...   \n21  mushroom_1.json  You are helping users understand an ML model's...   \n22       pdf_1.json  You are helping users understand an ML model's...   \n23       pdf_1.json  You are helping users understand an ML model's...   \n24       pdf_1.json  You are helping users understand an ML model's...   \n25       pdf_1.json  You are helping users understand an ML model's...   \n26   student_1.json  You are helping users understand an ML model's...   \n27   student_1.json  You are helping users understand an ML model's...   \n28   student_1.json  You are helping users understand an ML model's...   \n29   student_1.json  You are helping users understand an ML model's...   \n\n    total score  accuracy  completeness  fluency  conciseness  n_few_shot  \\\n0          14.2       4.0           4.0      2.2          4.0         NaN   \n1          13.8       4.0           3.6      2.2          4.0         NaN   \n2          14.6       4.0           4.0      2.6          4.0         NaN   \n3          15.0       3.2           4.0      3.8          4.0         NaN   \n4          13.8       3.2           3.2      3.4          4.0         NaN   \n5          14.4       3.2           4.0      3.2          4.0         NaN   \n6          15.0       4.0           4.0      3.0          4.0         NaN   \n7          14.6       4.0           3.6      3.0          4.0         NaN   \n8          15.0       4.0           4.0      3.0          4.0         NaN   \n9          15.0       4.0           4.0      3.0          4.0         1.0   \n10         15.0       4.0           4.0      3.0          4.0         3.0   \n11         15.0       4.0           4.0      3.0          4.0         5.0   \n12         14.6       3.2           4.0      3.4          4.0         1.0   \n13         14.8       3.2           4.0      3.6          4.0         3.0   \n14         15.0       3.2           4.0      3.8          4.0         5.0   \n15         14.8       4.0           3.6      3.2          4.0         1.0   \n16         13.8       4.0           2.8      3.0          4.0         3.0   \n17         14.8       4.0           3.6      3.2          4.0         5.0   \n18         15.0       4.0           4.0      3.0          4.0         0.0   \n19         15.0       4.0           4.0      3.0          4.0         0.0   \n20         15.0       4.0           4.0      3.0          4.0         3.0   \n21         15.0       4.0           4.0      3.0          4.0         3.0   \n22         14.6       3.2           4.0      3.4          4.0         0.0   \n23         15.4       4.0           4.0      3.4          4.0         0.0   \n24         14.6       3.2           4.0      3.4          4.0         3.0   \n25         15.4       4.0           4.0      3.4          4.0         3.0   \n26         15.2       4.0           4.0      3.2          4.0         0.0   \n27         15.2       4.0           4.0      3.2          4.0         0.0   \n28         15.2       4.0           4.0      3.2          4.0         3.0   \n29         15.2       4.0           4.0      3.2          4.0         3.0   \n\n    n_bootstrapped_few_shot  \n0                       NaN  \n1                       NaN  \n2                       NaN  \n3                       NaN  \n4                       NaN  \n5                       NaN  \n6                       NaN  \n7                       NaN  \n8                       NaN  \n9                       NaN  \n10                      NaN  \n11                      NaN  \n12                      NaN  \n13                      NaN  \n14                      NaN  \n15                      NaN  \n16                      NaN  \n17                      NaN  \n18                      3.0  \n19                      5.0  \n20                      3.0  \n21                      5.0  \n22                      3.0  \n23                      5.0  \n24                      3.0  \n25                      5.0  \n26                      3.0  \n27                      5.0  \n28                      3.0  \n29                      5.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset</th>\n      <th>prompt</th>\n      <th>total score</th>\n      <th>accuracy</th>\n      <th>completeness</th>\n      <th>fluency</th>\n      <th>conciseness</th>\n      <th>n_few_shot</th>\n      <th>n_bootstrapped_few_shot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.2</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.2</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users who do not have experien...</td>\n      <td>13.8</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>2.2</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.6</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>2.6</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.8</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users who do not have experien...</td>\n      <td>13.8</td>\n      <td>3.2</td>\n      <td>3.2</td>\n      <td>3.4</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.4</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>student_1.json</td>\n      <td>You are helping users who do not have experien...</td>\n      <td>14.6</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.6</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.4</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.8</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.8</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.8</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>13.8</td>\n      <td>4.0</td>\n      <td>2.8</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.8</td>\n      <td>4.0</td>\n      <td>3.6</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>mushroom_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.6</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.4</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.4</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.4</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>14.6</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.4</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>pdf_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.4</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.4</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.2</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.2</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.2</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>student_1.json</td>\n      <td>You are helping users understand an ML model's...</td>\n      <td>15.2</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.2</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
