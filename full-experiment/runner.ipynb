{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-20T16:21:29.847789Z",
     "start_time": "2024-08-20T16:21:28.409384Z"
    }
   },
   "source": [
    "import examples, core \n",
    "import os\n",
    "import yaml\n",
    "import dspy\n",
    "import metrics"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "\n",
    "llm = dspy.OpenAI(model='gpt-4o', api_key=openai_api_key, max_tokens=2000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T16:21:29.863792Z",
     "start_time": "2024-08-20T16:21:29.848774Z"
    }
   },
   "id": "6e9d56b95001b3ac",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T16:21:29.878863Z",
     "start_time": "2024-08-20T16:21:29.868855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = examples.load_examples(\"examples.json\")\n",
    "\n",
    "exp_metrics = metrics.Metrics(\n",
    "            [\n",
    "                metrics.accuracy,\n",
    "                metrics.fluency,\n",
    "                metrics.conciseness,\n",
    "                metrics.context_awareness,\n",
    "            ], verbose=1\n",
    "        )\n",
    "\n",
    "explingo = core.Explingo(llm=llm, context=\"The model predicts house prices\", \n",
    "                         examples=data, metric=exp_metrics)"
   ],
   "id": "75a9fcd3ad0e9975",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T16:21:29.894489Z",
     "start_time": "2024-08-20T16:21:29.880862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_explanations = [d.explanation for d in data]\n",
    "test_explanation_format = data[0].explanation_format\n",
    "\n",
    "gold_standards = [d for d in data if hasattr(d, \"narrative\")]"
   ],
   "id": "66031abf3885cb9a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T16:22:25.968021Z",
     "start_time": "2024-08-20T16:22:25.948497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VERIFY = True\n",
    "\n",
    "if VERIFY:\n",
    "    ver_metrics = metrics.Metrics(\n",
    "            [\n",
    "                metrics.accuracy,\n",
    "                metrics.fluency,\n",
    "                metrics.conciseness,\n",
    "            ], \n",
    "        verbose=0, \n",
    "        metric_kwargs={\"conciseness\": {\"max_optimal_length\": 150}}\n",
    "    )\n",
    "    print(ver_metrics(gold_standards[0], gold_standards[0]))"
   ],
   "id": "4b38609ff7969130",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.35, accuracy       2.00\n",
      "fluency        1.00\n",
      "conciseness    1.35\n",
      "dtype: float64)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BASIC PROMPTING\n",
    "\n",
    "TODO: update Explingo's prompting method to take in multiple different prompt options. \n",
    "DSPy does not support this by default, but we are using DSPy's evaluations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b5694bfd440f310"
  },
  {
   "cell_type": "code",
   "source": "explingo.run_experiment(test_explanations, test_explanation_format, prompt_type=\"basic\", max_iters=5)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T16:16:54.022505Z",
     "start_time": "2024-08-20T16:16:53.658421Z"
    }
   },
   "id": "1be61df6a728fa29",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Example' object has no attribute 'bad_narrative'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mexplingo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_explanations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_explanation_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbasic\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\github\\Explingo\\full-experiment\\core.py:114\u001B[0m, in \u001B[0;36mExplingo.run_experiment\u001B[1;34m(self, explanations, explanation_format, prompt_type, prompt, max_iters)\u001B[0m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m exp \u001B[38;5;129;01min\u001B[39;00m explanations:\n\u001B[0;32m    111\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\n\u001B[0;32m    112\u001B[0m         prompt\u001B[38;5;241m=\u001B[39mprompt, explanation\u001B[38;5;241m=\u001B[39mexp, explanation_format\u001B[38;5;241m=\u001B[39mexplanation_format\n\u001B[0;32m    113\u001B[0m     )\n\u001B[1;32m--> 114\u001B[0m     score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    115\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdspy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexplanation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexplanation_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexplanation_format\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m     total_score \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m score[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    119\u001B[0m     total_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\github\\Explingo\\full-experiment\\metrics.py:36\u001B[0m, in \u001B[0;36mMetrics.__call__\u001B[1;34m(self, gold, pred, trace)\u001B[0m\n\u001B[0;32m     34\u001B[0m metrics \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m metric \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric_funcs:\n\u001B[1;32m---> 36\u001B[0m     metrics[metric\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mmetric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m total_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(metrics\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\github\\Explingo\\full-experiment\\metrics.py:104\u001B[0m, in \u001B[0;36mfluency\u001B[1;34m(gold, pred, trace)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfluency\u001B[39m(gold, pred, trace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    102\u001B[0m     question \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHow natural and human does the narrative sound?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    103\u001B[0m     rubric \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 104\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0: Not at all natural (Example: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mgold\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbad_narrative\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m). \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    105\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1: Somewhat natural. 2: Natural ((Example: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgold\u001B[38;5;241m.\u001B[39mnarrative\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    106\u001B[0m     )\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m compute_score_from_rubric(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfluency\u001B[39m\u001B[38;5;124m\"\u001B[39m, question, rubric, pred\u001B[38;5;241m.\u001B[39mnarrative)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dspy\\primitives\\example.py:24\u001B[0m, in \u001B[0;36mExample.__getattr__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store:\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store[key]\n\u001B[1;32m---> 24\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Example' object has no attribute 'bad_narrative'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "explingo.run_experiment(test_explanations, test_explanation_format, prompt_type=\"few-shot\", max_iters=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T16:16:54.023407Z",
     "start_time": "2024-08-20T16:16:54.023407Z"
    }
   },
   "id": "c57212f361799ac6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "explingo.run_experiment(test_explanations, test_explanation_format, prompt_type=\"bootstrap-few-shot\", max_iters=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T16:16:54.025405Z",
     "start_time": "2024-08-20T16:16:54.024404Z"
    }
   },
   "id": "7bb946a284aff621",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-20T16:16:54.026405Z",
     "start_time": "2024-08-20T16:16:54.026405Z"
    }
   },
   "id": "1f8dc850abb3fc63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
