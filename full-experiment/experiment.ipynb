{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:08:41.761616Z",
     "start_time": "2024-08-14T20:08:40.538279Z"
    }
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "import yaml\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\", \"keys.yaml\"), \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    openai_api_key = config[\"openai_api_key\"]\n",
    "\n",
    "llm = dspy.OpenAI(model='gpt-4', api_key=openai_api_key)\n",
    "dspy.settings.configure(lm=llm, experimental=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:08:41.766503Z",
     "start_time": "2024-08-14T20:08:41.762621Z"
    }
   },
   "id": "eec7e1c90485384",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Explingo(dspy.Signature):\n",
    "    \"\"\" You are helping users understand an ML model's prediction. Given an explanation and information about the model,\n",
    "    convert the explanation into a human-readable narrative.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"what the ML model predicts\")\n",
    "    explanation = dspy.InputField(desc=\"explanation of an ML model's prediction\")\n",
    "    explanation_format = dspy.InputField(desc=\"format the explanation is given in\")\n",
    "\n",
    "    narrative = dspy.OutputField(\n",
    "        desc=\"human-readable narrative version of the explanation\"\n",
    "    )\n",
    "    rationalization = dspy.OutputField(\n",
    "       desc=\"explains why given features may be relevant\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:08:41.778209Z",
     "start_time": "2024-08-14T20:08:41.766503Z"
    }
   },
   "id": "f8b6001c19aefdc5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "narrify = dspy.Predict(Explingo)\n",
    "result = narrify(context=\"The ML model predicts house prices\", \n",
    "                 explanation=\"(total size in square feet, 300, -12000), (number of bedrooms, 2, -8000)\",\n",
    "                 explanation_format=\"(feature name, feature value, SHAP contribution in $)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:08:49.663717Z",
     "start_time": "2024-08-14T20:08:41.778209Z"
    }
   },
   "id": "17b25640996183bb",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_example(convo):\n",
    "      example = dspy.Example(explanation=convo[\"explanation\"],\n",
    "                             context=convo[\"context\"],\n",
    "                             explanation_format=convo[\"explanation_format\"])\n",
    "      if \"description\" in convo:\n",
    "        example.narrative = convo[\"description\"]\n",
    "      if \"bad_description\" in convo:\n",
    "        example.bad_narrative = convo[\"bad_description\"]\n",
    "      return example.with_inputs(\"explanation\", \"context\", \"explanation_format\")\n",
    "\n",
    "training_data = json.load(open(\"examples.json\", \"r\"))\n",
    "examples = []\n",
    "for convo in training_data:\n",
    "  examples.append(create_example(convo))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:08:49.668350Z",
     "start_time": "2024-08-14T20:08:49.664723Z"
    }
   },
   "id": "35fed04f88041ee4",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "grader = dspy.OpenAI(model=\"gpt-4-1106-preview\", max_tokens=1000, model_type=\"chat\")\n",
    "\n",
    "class RubricAssess(dspy.Signature):\n",
    "    \"\"\"Assess a narrative based on a rubric.\"\"\"\n",
    "\n",
    "    narrative = dspy.InputField()\n",
    "    question = dspy.InputField()\n",
    "    rubric = dspy.InputField()\n",
    "\n",
    "    assessment = dspy.OutputField(\n",
    "        desc=\"0, 1, or 2, based on the rubric. Include only the number.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class BooleanAssess(dspy.Signature):\n",
    "    \"\"\"Assess a narrative with a yes/no question.\"\"\"\n",
    "\n",
    "    narrative = dspy.InputField()\n",
    "    question = dspy.InputField()\n",
    "\n",
    "    assessment = dspy.OutputField(desc=\"yes or no\")\n",
    "\n",
    "\n",
    "def compute_score_from_boolean(metric, question, narrative, iters=10):\n",
    "    total_score = 0\n",
    "\n",
    "    with dspy.context(lm=grader):\n",
    "        for i in range(iters):\n",
    "            score = dspy.Predict(BooleanAssess)(\n",
    "                question=question, narrative=narrative\n",
    "            ).assessment\n",
    "            if score == \"yes\":\n",
    "                total_score += 1\n",
    "    score = total_score / iters\n",
    "\n",
    "    if 0.3 < score < 0.7:\n",
    "        print(\"Inconsistent score for metric %s: %s\" % (metric, score))\n",
    "\n",
    "    return score * 2\n",
    "\n",
    "\n",
    "def compute_score_from_rubric(metric, question, rubric, narrative, iters=5):\n",
    "    scores = []\n",
    "\n",
    "    with dspy.context(lm=grader):\n",
    "        for i in range(iters):\n",
    "            score = dspy.Predict(RubricAssess)(\n",
    "                question=question,\n",
    "                rubric=rubric,\n",
    "                narrative=narrative,\n",
    "            ).assessment\n",
    "            scores.append(int(score))\n",
    "\n",
    "    if 0 in scores and 2 in scores:\n",
    "        print(\"Inconsistent score for metric %s: %s\" % (metric, scores))\n",
    "\n",
    "    return sum(scores) / iters\n",
    "\n",
    "\n",
    "def accuracy(gold, pred, trace=None):\n",
    "    question = f\"How accurately does the narrative describe this explanation: {gold.explanation}?. The explanation is formatted at: {gold.explanation_format}\"\n",
    "    rubric = f\"0: Contain an error. 1: Accurate, but misleading. 2: Accurate and clear.\"\n",
    "    return compute_score_from_rubric(\"accuracy\", question, rubric, pred.narrative)\n",
    "\n",
    "\n",
    "def fluency(gold, pred, trace=None):\n",
    "    question = f\"How natural and human does the narrative sound?\"\n",
    "    rubric = f\"0: Not at all natural. 1: Somewhat natural. 2: Natural.\"\n",
    "    return compute_score_from_rubric(\"fluency\", question, rubric, pred.narrative)\n",
    "\n",
    "\n",
    "def completeness(gold, pred, trace=None):\n",
    "    question = f\"Does the narrative contain all the feature values from this explanation? {gold.explanation}? The explanation is formatted at: {gold.explanation_format}\"\n",
    "    return compute_score_from_boolean(\"completeness\", question, pred.narrative)\n",
    "\n",
    "\n",
    "def conciseness(gold, pred, trace=None):\n",
    "    length = len(pred.narrative.split())\n",
    "    # scale length between 0 and 2, such that longer lengths score lower\n",
    "    return 2 - min(length / 50, 2)\n",
    "\n",
    "\n",
    "def context_awareness(gold, pred, trace=None):\n",
    "    question = (\n",
    "        f\"How well does the narrative rationalization help explain the model's logic?\"\n",
    "    )\n",
    "    rubric = f\"0: Not at all. 1: Somewhat. 2: Very well.\"\n",
    "    return compute_score_from_rubric(\n",
    "        \"context_awareness\", question, rubric, pred.rationalization\n",
    "    )\n",
    "\n",
    "def all_metrics(gold, pred, trace=None, verbose=False):\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy(gold, pred, trace),\n",
    "        \"fluency\": fluency(gold, pred, trace),\n",
    "        \"completeness\": completeness(gold, pred, trace),\n",
    "        \"conciseness\": conciseness(gold, pred, trace),\n",
    "        \"context_awareness\": context_awareness(gold, pred, trace),\n",
    "    }\n",
    "    \n",
    "    total_score = sum(metrics.values())\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Explanation:\", gold.explanation)\n",
    "        print(\"Narrative:\", pred.narrative)\n",
    "        print(\"Rationalization:\", pred.rationalization)\n",
    "        print(\"Total Score:\", total_score)\n",
    "        print(\"\".join(\n",
    "            f\"{metric}: {score}, \" for metric, score in metrics.items()))\n",
    "        print(\"--\")\n",
    "\n",
    "    if trace is None:\n",
    "        return total_score\n",
    "    else:\n",
    "        # For bootstrapping, only consider this narrative acceptable if it is completely accurate and score 8 or higher\n",
    "        return (metrics[\"accuracy\"] == 2) and (total_score >= 8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:08:49.680901Z",
     "start_time": "2024-08-14T20:08:49.668350Z"
    }
   },
   "id": "9581b697cd53bc8",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: (Above ground living area square feet, 1256.00, -12527.46), (Rates the overall material and finish of the house, 5.00, -10743.76), (Second floor square feet, 0.00, -10142.29), (Physical locations within Ames city limits, Edwards, -9913.81), (Wood deck area in square feet, 736.00, 9846.38)\n",
      "Narrative: The machine learning model predicts house prices based on several factors. The most significant factors include the above ground living area, the overall material and finish of the house, the size of the second floor, the location within Ames city limits, and the size of the wood deck area. For instance, a house with an above ground living area of 1256 square feet, an overall material and finish rating of 5, no second floor, located in Edwards, and with a wood deck area of 736 square feet would have a certain predicted price.\n",
      "Rationalization: The above ground living area is a significant factor because larger houses tend to be more expensive. The overall material and finish of the house is also important as higher quality materials and\n",
      "Total Score: 4.14\n",
      "accuracy: 2.0, fluency: 1.0, completeness: 0.0, conciseness: 0.1399999999999999, context_awareness: 1.0, \n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    example = examples[i]\n",
    "    pred = narrify(**example.inputs())\n",
    "    all_metrics(example, pred, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:08:59.811621Z",
     "start_time": "2024-08-14T20:08:49.681416Z"
    }
   },
   "id": "27223fc571985517",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [05:41<00:00, 13.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 25 examples in round 0.\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "bootstrap = BootstrapFewShot(metric=all_metrics)\n",
    "narrify_optimized = bootstrap.compile(narrify, trainset=examples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:14:41.827611Z",
     "start_time": "2024-08-14T20:08:59.812628Z"
    }
   },
   "id": "4015f77c583c3ee9",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T20:14:41.830090Z",
     "start_time": "2024-08-14T20:14:41.828617Z"
    }
   },
   "id": "f8078e2fbc990880",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
